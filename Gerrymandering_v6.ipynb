{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colonial-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>abbr</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05</td>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08</td>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09</td>\n",
       "      <td>CT</td>\n",
       "      <td>Connecticut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>DE</td>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>DC</td>\n",
       "      <td>District of Columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>FL</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>GA</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>HI</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>ID</td>\n",
       "      <td>Idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>IL</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>IN</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19</td>\n",
       "      <td>IA</td>\n",
       "      <td>Iowa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>KS</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>KY</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22</td>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23</td>\n",
       "      <td>ME</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27</td>\n",
       "      <td>MN</td>\n",
       "      <td>Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28</td>\n",
       "      <td>MS</td>\n",
       "      <td>Mississippi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29</td>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>MT</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>NV</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33</td>\n",
       "      <td>NH</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>34</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>35</td>\n",
       "      <td>NM</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>36</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>37</td>\n",
       "      <td>NC</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>38</td>\n",
       "      <td>ND</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>39</td>\n",
       "      <td>OH</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>40</td>\n",
       "      <td>OK</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>41</td>\n",
       "      <td>OR</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>42</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44</td>\n",
       "      <td>RI</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>45</td>\n",
       "      <td>SC</td>\n",
       "      <td>South Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>46</td>\n",
       "      <td>SD</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>47</td>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>48</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>49</td>\n",
       "      <td>UT</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>50</td>\n",
       "      <td>VT</td>\n",
       "      <td>Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>51</td>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>53</td>\n",
       "      <td>WA</td>\n",
       "      <td>Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>54</td>\n",
       "      <td>WV</td>\n",
       "      <td>West Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>55</td>\n",
       "      <td>WI</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>56</td>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>60</td>\n",
       "      <td>AS</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>66</td>\n",
       "      <td>GU</td>\n",
       "      <td>Guam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>69</td>\n",
       "      <td>MP</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>72</td>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>74</td>\n",
       "      <td>UM</td>\n",
       "      <td>U.S. Minor Outlying Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>78</td>\n",
       "      <td>VI</td>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fips abbr                         name\n",
       "0    01   AL                      Alabama\n",
       "1    02   AK                       Alaska\n",
       "2    04   AZ                      Arizona\n",
       "3    05   AR                     Arkansas\n",
       "4    06   CA                   California\n",
       "5    08   CO                     Colorado\n",
       "6    09   CT                  Connecticut\n",
       "7    10   DE                     Delaware\n",
       "8    11   DC         District of Columbia\n",
       "9    12   FL                      Florida\n",
       "10   13   GA                      Georgia\n",
       "11   15   HI                       Hawaii\n",
       "12   16   ID                        Idaho\n",
       "13   17   IL                     Illinois\n",
       "14   18   IN                      Indiana\n",
       "15   19   IA                         Iowa\n",
       "16   20   KS                       Kansas\n",
       "17   21   KY                     Kentucky\n",
       "18   22   LA                    Louisiana\n",
       "19   23   ME                        Maine\n",
       "20   24   MD                     Maryland\n",
       "21   25   MA                Massachusetts\n",
       "22   26   MI                     Michigan\n",
       "23   27   MN                    Minnesota\n",
       "24   28   MS                  Mississippi\n",
       "25   29   MO                     Missouri\n",
       "26   30   MT                      Montana\n",
       "27   31   NE                     Nebraska\n",
       "28   32   NV                       Nevada\n",
       "29   33   NH                New Hampshire\n",
       "30   34   NJ                   New Jersey\n",
       "31   35   NM                   New Mexico\n",
       "32   36   NY                     New York\n",
       "33   37   NC               North Carolina\n",
       "34   38   ND                 North Dakota\n",
       "35   39   OH                         Ohio\n",
       "36   40   OK                     Oklahoma\n",
       "37   41   OR                       Oregon\n",
       "38   42   PA                 Pennsylvania\n",
       "39   44   RI                 Rhode Island\n",
       "40   45   SC               South Carolina\n",
       "41   46   SD                 South Dakota\n",
       "42   47   TN                    Tennessee\n",
       "43   48   TX                        Texas\n",
       "44   49   UT                         Utah\n",
       "45   50   VT                      Vermont\n",
       "46   51   VA                     Virginia\n",
       "47   53   WA                   Washington\n",
       "48   54   WV                West Virginia\n",
       "49   55   WI                    Wisconsin\n",
       "50   56   WY                      Wyoming\n",
       "51   60   AS               American Samoa\n",
       "52   66   GU                         Guam\n",
       "53   69   MP     Northern Mariana Islands\n",
       "54   72   PR                  Puerto Rico\n",
       "55   74   UM  U.S. Minor Outlying Islands\n",
       "56   78   VI          U.S. Virgin Islands"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell defines the Gerry class which does all the work\n",
    "# I don't think you will need to edit this cell at all\n",
    "proj_id = 'cmat-315920'\n",
    "root_path = '/home/jupyter'\n",
    "\n",
    "import google, pathlib, shutil, time, datetime, dataclasses, typing, numpy as np, pandas as pd, geopandas as gpd, networkx as nx\n",
    "import matplotlib.pyplot as plt, plotly.express as px \n",
    "from shapely.ops import orient\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient, types\n",
    "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
    "\n",
    "cred, proj = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "bqclient = bigquery.Client(credentials = cred, project = proj)\n",
    "crs_map = 'NAD83'\n",
    "crs_area = 'ESRI:102003'\n",
    "crs_length = 'ESRI:102005'\n",
    "# input is WKT in NAD83 - https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2020/TGRSHP2020_TechDoc_Ch3.pdf\n",
    "# use ESRI:102003 for area calculations - https://epsg.io/102003\n",
    "# use ESRI:102005 for length calculations - https://epsg.io/102005\n",
    "\n",
    "def get_states():\n",
    "    qry = f\"\"\"\n",
    "    select\n",
    "        state_fips_code as fips\n",
    "        , state_postal_abbreviation as abbr\n",
    "        , state_name as name\n",
    "    from\n",
    "        bigquery-public-data.census_utility.fips_codes_states\n",
    "    \"\"\"\n",
    "    return bqclient.query(qry).result().to_dataframe()\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Gerry:\n",
    "    # These are default values that can be overridden when you create the object\n",
    "    abbr              : str\n",
    "    yr                : int\n",
    "    geo_simplification: float = 0.003\n",
    "    min_graph_degree  : int = 1\n",
    "    pop_err_max_pct   : float = 2.0\n",
    "    seed              : int = 42\n",
    "    overwrite         : typing.Any = False\n",
    "    clr_seq           : typing.Any = tuple(px.colors.qualitative.Antique)\n",
    "    # px.colors.qualitative.swatches() # shows available color schemes\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.__dict__[key]\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        self.__dict__[key] = val\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self['rng'] = np.random.default_rng(self['seed'])\n",
    "        self['congress'] = int((self['yr']-1786)/2)\n",
    "        self['races'] = ['total', 'white', 'black', 'asian', 'hispanic', 'amerindian', 'other_race', 'two_or_more_races']\n",
    "        self['race_pops'] = [f'{r}_pop' for r in self['races']]\n",
    "        I = [10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 60000, 75000, 100000, 125000, 150000, 200000]\n",
    "        self['income_levels'] = [f'income_less_{I[0]}'] + [f'income_{I[j]}_{I[j+1]-1}' for j in range(len(I)-1)] + [f'income_{I[-1]}_or_more']\n",
    "        def rgb_to_hex(c):\n",
    "            if c[0] == '#':\n",
    "                return c\n",
    "            else:\n",
    "                return '#%02x%02x%02x' % tuple(int(rgb) for rgb in c[4:-1].split(', '))\n",
    "        self['clr_seq'] = [rgb_to_hex(c) for c in self['clr_seq']]\n",
    "        \n",
    "        self.__dict__.update(states[states['abbr']==self['abbr']].iloc[0])\n",
    "        self['run_path'] = pathlib.Path(f'{root_path}/simulations/{self[\"yr\"]}/{self[\"abbr\"]}')\n",
    "        self['run_path'].mkdir(parents=True, exist_ok=True)\n",
    "        self['files'] = {'bgs'  : self['run_path'] / 'bgs.parquet',\n",
    "                         'pairs': self['run_path'] / 'pairs.parquet',\n",
    "                         'graph': self['run_path'] / 'graph.gpickle',\n",
    "                        }\n",
    "        if self['overwrite'] is True or str(self['overwrite']).lower() == 'all':\n",
    "            O = self['files'].keys()\n",
    "        elif self['overwrite'] is False or self['overwrite'] is None or self['overwrite'] == '' or self['overwrite'] == []:\n",
    "            O = []\n",
    "        else:\n",
    "            O = self['overwrite']\n",
    "        for key in O:\n",
    "            try:\n",
    "                f = self['files'][key]\n",
    "                f.unlink()\n",
    "                print(f'unlinked {f}')\n",
    "            except:\n",
    "                print(f'No file associated to \"{key}\" found')\n",
    "\n",
    "        self.get_bgs()\n",
    "        return\n",
    "        self['bgs'].insert(3, 'step', 0)\n",
    "        self['total_pop']  = self['bgs']['total_pop'].sum()\n",
    "        self['cd_names'] = np.unique(self['bgs']['cd'])\n",
    "        self['cd_count'] = len(self.cd_names)\n",
    "        self['pop_target'] = self.total_pop / self.cd_count\n",
    "        self['pop_err_max'] =  self.total_pop * self.pop_err_max_pct / 100\n",
    "        self.get_bgs()\n",
    "        self.get_pairs()\n",
    "        self['transit_denom'] = 100\n",
    "        self.compute_stats()\n",
    "        self['transit_denom'] = self['stats']['cd_transit'].sum()\n",
    "\n",
    "    def set_dtypes(self, df):\n",
    "        # does NOT work inplace\n",
    "        dtypes = {'geo_id':str, 'step':np.uint16,\n",
    "                  'state_fips':np.uint8, 'county_fips':np.uint8,'tract_ce':np.uint32, 'blockgroup_ce':np.uint8,\n",
    "                  'cd_orig':np.uint8, 'cd':np.uint8,\n",
    "                  'lon':np.float64, 'lat':np.float64, 'distance':np.float64,\n",
    "                  'total_pop':np.uint32, 'cd_pop':np.uint32,\n",
    "                  'area':np.float64, 'cd_area':np.float64,\n",
    "                  'perim':np.float64, 'cd_perim':np.float64, 'perim_shared':np.float64, 'touch':bool,\n",
    "                  'cd_polsby':np.float64, 'transit':np.float64, 'cd_transit':np.float64,\n",
    "                 }\n",
    "        for V in ['race_pops', 'income_levels']:\n",
    "            dtypes.update({x:np.uint32 for x in self[V]})\n",
    "            dtypes.update({f'cd_{x}':np.uint32 for x in self[V]})\n",
    "        return df.astype({c:d for c,d in dtypes.items() if c in df.columns}, copy=False)\n",
    "\n",
    "    def to_crs(self, df, crs):\n",
    "        # works inplace\n",
    "        df.to_crs(crs=crs, inplace=True)\n",
    "        for c in df.columns:\n",
    "            if c[:8] in ['geometry', 'centroid']:\n",
    "                df[c] = df[c].to_crs(crs=crs)\n",
    "        return df\n",
    "\n",
    "    def read_data(self, variable):\n",
    "        \"\"\"Check if the data already exists so we can reuse it without pulling it again\"\"\"\n",
    "        try:\n",
    "            # Does the object already have it?\n",
    "            self[variable]\n",
    "        except:\n",
    "            # If not, is it stored in a local file?\n",
    "            print(f'Getting {variable} - ', end='')\n",
    "            f = self['files'][variable]\n",
    "            try:\n",
    "                self[variable] = gpd.read_parquet(f)\n",
    "                print(f'found {f}')\n",
    "            except:\n",
    "                try:\n",
    "                    self[variable] = pd.read_parquet(f)\n",
    "                    print(f'found {f}')\n",
    "                except:\n",
    "                    try:\n",
    "                        self[variable] = nx.read_gpickle(f)\n",
    "                        print(f'found {f}')\n",
    "                    except:\n",
    "                        # Nope, there's no file with that data ... gotta go get it\n",
    "                        print('no local file found - compiling from source')\n",
    "                        return False\n",
    "        return True\n",
    "    \n",
    "    def find_closest(self, point, others):\n",
    "        d = others.distance(point)\n",
    "        return others.loc[d.idxmin()]\n",
    "\n",
    "    def get_bgs(self):\n",
    "        if self.read_data('bgs'):\n",
    "            self['bgs'] = self.set_dtypes(self.to_crs(self['bgs'], crs_map))\n",
    "        else:\n",
    "            qry = f\"\"\"\n",
    "            select\n",
    "                --geo_id structure - https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html\n",
    "                *\n",
    "            from (\n",
    "                select\n",
    "                    *\n",
    "                from (\n",
    "                    -- get shapes demographic data\n",
    "                    select distinct\n",
    "                        geo_id as geo_id\n",
    "                        , cast(substring(geo_id, 0 , 2) as int) as state_fips\n",
    "                        , cast(substring(geo_id, 3 , 3) as int) as county_fips\n",
    "                        , cast(substring(geo_id, 5 , 6) as int) as tract_ce\n",
    "                        , cast(substring(geo_id, 12, 1) as int) as blockgroup_ce\n",
    "                        , {\", \".join(self['race_pops'])}\n",
    "                        , {\", \".join(self['income_levels'])}\n",
    "                    from\n",
    "                        bigquery-public-data.census_bureau_acs.blockgroup_{self['yr']}_5yr\n",
    "                    where\n",
    "                        left(geo_id, 2) = \"{self['fips']}\"\n",
    "                    ) as acs\n",
    "                full outer join (\n",
    "                    -- get shapes\n",
    "                    select\n",
    "                        geo_id as geo_id_geo\n",
    "                        , blockgroup_geom as geometry\n",
    "                    from\n",
    "                        bigquery-public-data.geo_census_blockgroups.blockgroups_{self['fips']}\n",
    "                    ) as geo\n",
    "                on\n",
    "                    acs.geo_id = geo.geo_id_geo\n",
    "                ) as acs_geo\n",
    "            full outer join (\n",
    "                select\n",
    "                    *\n",
    "                from (\n",
    "                    -- get population weighted centroids\n",
    "                    -- must build geo_id because data source does not include it\n",
    "                    select distinct\n",
    "                        concat( \n",
    "                            lpad(cast(STATEFP as string), 2, \"0\"),\n",
    "                            lpad(cast(COUNTYFP as string), 3, \"0\"),\n",
    "                            lpad(cast(TRACTCE as string), 6, \"0\"),\n",
    "                            lpad(cast(BLKGRPCE as string), 1, \"0\")\n",
    "                            ) as geo_id_centroids\n",
    "                        , LONGITUDE as lon\n",
    "                        , LATITUDE as lat\n",
    "                    from\n",
    "                        {proj_id}.BLOCKGROUP_CENTROIDS.blockgroup_centroids_{self['fips']}\n",
    "                    ) as centroids\n",
    "                full outer join (\n",
    "                    -- get congressional district\n",
    "                    -- at block level -> must aggregate to blockgroup\n",
    "                    -- 7141 (3%) of blockgroups span multiple congressional districts\n",
    "                    -- We assign that entire bg to the cd with the most blocks\n",
    "                    select\n",
    "                        geo_id_cd\n",
    "                        , cd\n",
    "                    from (\n",
    "                        select\n",
    "                            A.*\n",
    "                            , rank() over (partition by A.geo_id_cd order by A.num_blocks_in_cd desc) as r\n",
    "                        from (\n",
    "                            select\n",
    "                                left(BLOCKID, 12) as geo_id_cd   -- remove last 4 char to get blockgroup geo_id\n",
    "                                , CD{self['congress']} as cd\n",
    "                                , count(*) as num_blocks_in_cd\n",
    "                            from \n",
    "                                {proj_id}.Block_Equivalency_Files.{self['congress']}th_BEF\n",
    "                            where\n",
    "                                left(blockid, 2) = \"{self['fips']}\"\n",
    "                            group by\n",
    "                                1, 2\n",
    "                            ) as A\n",
    "                        ) as B\n",
    "                    where\n",
    "                        r = 1\n",
    "                    ) as cd\n",
    "                on\n",
    "                    centroids.geo_id_centroids = cd.geo_id_cd\n",
    "                ) as centroids_cd\n",
    "            on acs_geo.geo_id = centroids_cd.geo_id_cd\n",
    "            \"\"\"\n",
    "            bgs = bqclient.query(qry).result().to_dataframe()\n",
    "            bgs['geometry'] = gpd.GeoSeries.from_wkt(bgs['geometry']).apply(lambda p: orient(p, -1))\n",
    "            bgs['centroid'] = gpd.points_from_xy(bgs['lon'], bgs['lat'], crs=crs_map)\n",
    "            bgs = gpd.GeoDataFrame(bgs, geometry='geometry', crs=crs_map)\n",
    "#             bgs['area']  = self.to_crs(bgs, crs_area).area / 1000 / 1000\n",
    "#             bgs['perim'] = self.to_crs(bgs, crs_length).length / 1000\n",
    "            \n",
    "            self.to_crs(bgs, crs_length)\n",
    "            \n",
    "            # fix mismatches\n",
    "            cd_row_mask =   bgs['geo_id'].isnull() & ~bgs['geo_id_cd'].isnull()\n",
    "            acs_row_mask = ~bgs['geo_id'].isnull() &  bgs['geo_id_cd'].isnull()\n",
    "            if acs_row_mask.any() or cd_row_mask.any():\n",
    "                bgs_matched = bgs[~acs_row_mask & ~cd_row_mask]\n",
    "                cd_col_mask  = ~bgs[cd_row_mask] .isnull().any(axis=0)\n",
    "                acs_col_mask = ~bgs[acs_row_mask].isnull().any(axis=0)\n",
    "                acs_col_mask['centroid'] = False\n",
    "                A = bgs.loc[acs_row_mask, acs_col_mask]\n",
    "                B = bgs.loc[cd_row_mask , cd_col_mask ]\n",
    "                C = A.merge(B, how='cross')\n",
    "                C['match'] = C['geometry'].contains(C['centroid'])\n",
    "                def f(X):\n",
    "                    N = X['match'].sum()\n",
    "                    if N != 1:\n",
    "                        X['centroid'] = X['geometry'].centroid\n",
    "                        X['cd'] = np.nan  # fill later\n",
    "                    return X.nlargest(1, columns='match').drop(columns='match')\n",
    "                bgs_unmatched = C.groupby('geo_id').apply(f)\n",
    "                bgs = pd.concat([bgs_matched, bgs_unmatched], ignore_index=True)\n",
    "        \n",
    "            cd_qual = (bgs.groupby('cd')['total_pop'].transform('sum')) > 0\n",
    "            others = bgs[cd_qual]\n",
    "            for i, bg in bgs[~cd_qual].iterrows():\n",
    "                nbr = self.find_closest(bg['centroid'], others)\n",
    "                print(f\"Given cd for {bg['geo_id']} is {bg['cd']} ... changing to {nbr['cd']} based on nearest neighbor {nbr['geo_id']}\")\n",
    "                bgs.loc[i, 'cd'] = nbr['cd']\n",
    "            \n",
    "            t = bgs.pop('cd')\n",
    "            bgs.insert(1, 'cd_orig', t.copy())\n",
    "            bgs.insert(2, 'cd', t.copy())\n",
    "            self['bgs'] = self.set_dtypes(bgs.drop(columns=['geo_id_geo', 'geo_id_cd', 'geo_id_centroids']).sort_values(['cd', 'geo_id']))\n",
    "#             display(self['bgs'].groupby('cd')['total_pop'].agg(['count','sum']).sort_index())\n",
    "            mask = self['bgs'].isnull().any(axis=1)\n",
    "            assert ~mask.any(), f\"Found null values\\n{self['bgs'][mask]}\"\n",
    "            self['bgs'].to_parquet(self['files']['bgs'], index=False)\n",
    "            \n",
    "            return\n",
    "            self.get_pairs()\n",
    "            self.to_crs(self['bgs'], crs_map)\n",
    "            self['bgs']['geometry'] = self['bgs']['geometry'].simplify(self['geo_simplification'])\n",
    "            self['bgs'].to_parquet(self['files']['bgs'], index=False)\n",
    "\n",
    "    def get_pairs(self):\n",
    "        if self.read_data('pairs'):\n",
    "            self['pairs'] = self.set_dtypes(self['pairs'])\n",
    "        else:\n",
    "            cols = ['geo_id', 'geometry', 'centroid']\n",
    "            df = self.to_crs(self['bgs'], crs_length)[cols].copy()\n",
    "            print(0)\n",
    "            pairs = df.merge(df, how='cross').query('geo_id_x < geo_id_y')\n",
    "            print(1)\n",
    "            pairs['distance']     = pairs.set_geometry('centroid_x').distance(    pairs.set_geometry('centroid_y'), align=False) / 1000\n",
    "            print(2)\n",
    "            pairs['perim_shared'] = pairs.set_geometry('geometry_x').intersection(pairs.set_geometry('geometry_y'), align=False).length / 1000\n",
    "            print(3)\n",
    "            pairs['touch'] = pairs['perim_shared'] > 1e-4\n",
    "            print(4)\n",
    "            pairs['transit'] = pairs['distance'] / 1341 * self['rng'].uniform(0.5, 1.5)  # 50 mph → 1341 m/min\n",
    "            print(5)\n",
    "            self['pairs'] = self.set_dtypes(pairs.drop(columns=[c+z for c in cols[1:] for z in ['_x', '_y']]))\n",
    "            print(6)\n",
    "            self['pairs'].to_parquet(self['files']['pairs'], index=False)\n",
    "\n",
    "    def edges_to_graph(self, edges):\n",
    "        edge_attr=['transit']\n",
    "        return nx.from_pandas_edgelist(edges, source='geo_id_x', target='geo_id_y', edge_attr=edge_attr)\n",
    "\n",
    "    def get_graph(self):\n",
    "        if self.read_data('graph'):\n",
    "            pass\n",
    "        else:\n",
    "            edges = self['pairs'].query('touch')\n",
    "            self['graph'] = self.edges_to_graph(edges)\n",
    "            node_attr = ['cd', 'total_pop']\n",
    "            nx.set_node_attributes(self['graph'], self['bgs'].set_index('geo_id')[node_attr].to_dict('index'))\n",
    "\n",
    "            for cd, nodes in self['bgs'].groupby('cd')['geo_id']:\n",
    "                while True:\n",
    "                    H = self['graph'].subgraph(nodes)\n",
    "                    components = [list(c) for c in nx.connected_components(H)]\n",
    "                    if len(components) == 1:\n",
    "                        break\n",
    "                    print(f'CD {cd} has {len(components)} connected components ... adding edges to connect')\n",
    "                    qry = f'(geo_id_x in {components[0]} & geo_id_y in {components[1]}) | (geo_id_y in {components[0]} & geo_id_x in {components[1]})'\n",
    "                    cut_edges = self['pairs'].query(qry)\n",
    "                    edges = self['pairs'].query(f'distance == {cut_edges[\"distance\"].min()}')\n",
    "                    self['graph'].update(self.edges_to_graph(edges))\n",
    "\n",
    "            # ensure min degrees\n",
    "            edges = list()\n",
    "            for node, deg in self['graph'].degree:\n",
    "                k = self['min_graph_degree'] - deg\n",
    "                if k > 0:\n",
    "                    print(f'{node} has degree {deg} ... adding {k} more edge(s)')\n",
    "                    N = list(self['graph'].neighbors(node))\n",
    "                    df = self['pairs'].query(f'(geo_id_x == {node} & geo_id_y not in {N}) | (geo_id_y == {node} & geo_id_x not in {N})')\n",
    "                    edges.append(df.nsmallest(k, 'distance'))\n",
    "            if len(edges) > 0:\n",
    "                self['graph'].update(self.edges_to_graph(pd.concat(edges)))\n",
    "            nx.write_gpickle(self['graph'], self['files']['graph'])\n",
    "    \n",
    "    def get_cds(self):\n",
    "        return self['bgs'].groupby('cd')['geo_id'].apply(tuple).sort_index().to_dict()\n",
    "    \n",
    "    def get_hash(self):\n",
    "        return hash(tuple(self.get_cds().items()))\n",
    "\n",
    "    def compute_stats(self, step=None):\n",
    "        if step is not None:\n",
    "            self['bgs'] = self['bgs'].drop(columns=['cd','step']).merge(self['bgs_hist'].query(f'step == {step}'), on='geo_id')\n",
    "        def f(nodes):\n",
    "            n = nodes['geo_id'].tolist()\n",
    "            edges = self['pairs'].query(f'geo_id_x in {n} & geo_id_y in {n}')\n",
    "            s = {f'cd_{x}':nodes[x].sum() for x in ['area'] + self['race_pops'] + self['income_levels']}\n",
    "            s.update({'step'      : nodes['step'].max(),\n",
    "                      'cd_perim'  : nodes['perim'].sum() - 2 * edges['perim_shared'].sum(),\n",
    "                      'cd_transit': edges['transit'].sum() / self['transit_denom']  * 100,\n",
    "                     })\n",
    "            s.update({'cd_polsby' : (1 - 4 * np.pi * s['cd_area'] / (s['cd_perim']**2)) * 100})\n",
    "            return pd.Series(s)\n",
    "        stats = self['bgs'].groupby('cd').apply(f)\n",
    "        self['bgs'] = (self['bgs'].drop(columns=stats.columns, errors='ignore')\n",
    "                       .merge(stats, left_on='cd', right_index=True)\n",
    "                      )\n",
    "        self['bgs'] = self.set_dtypes(self['bgs'].sort_values('cd'))\n",
    "        self['stats'] = self.set_dtypes(stats.reset_index().sort_values('cd'))\n",
    "        return self['stats']\n",
    "    \n",
    "    def draw_map(self, step=None):\n",
    "        self.compute_stats(step)\n",
    "        step = 0 if step is None else step\n",
    "        df = self.to_crs(self['bgs'], crs_map).copy()\n",
    "        df['cd_total_pop'] = (df['cd_total_pop'] / self['total_pop'] * 100).round(1).astype(str)\n",
    "        df['cd_area'] = df['cd_area'].round(0).astype(int).astype(str)\n",
    "        df['cd_transit'] = df['cd_transit'].round(1).astype(str)\n",
    "        df['cd_polsby'] = df['cd_polsby'].round(1).astype(str)\n",
    "        df['cd'] = df['cd'].astype(str)\n",
    "        df['total_pop'] = df['total_pop'].round(0).astype(int).astype(str)\n",
    "        df['area'] = df['area'].round(0).astype(int).astype(str)\n",
    "        df['cd_stats'] = df['cd']+': pop='+df['cd_total_pop']+'%, area='+df['cd_area']+', tt='+df['cd_transit']+', pp='+df['cd_polsby']\n",
    "        fig = px.choropleth(df,\n",
    "                            geojson = df['geometry'],\n",
    "                            locations = df.index,\n",
    "                            color = \"cd_stats\",\n",
    "                            color_discrete_sequence = self['clr_seq'],\n",
    "                            hover_data = ['area', 'total_pop', 'lon', 'lat'],\n",
    "                           )\n",
    "        fig.update_geos(fitbounds=\"locations\", visible=True)\n",
    "        fig.update_layout({\n",
    "            'title'  : {'text':f'{self[\"name\"]} {self[\"yr\"]} step {step}', 'x':0.5, 'y':1.0},\n",
    "            'margin' : {'r':0, 't':20, 'l':0, 'b':0},\n",
    "            'legend' : {'y':0.5},\n",
    "        })\n",
    "        fig.show()\n",
    "\n",
    "    def draw_graph(self, step=None, layout=nx.spring_layout):\n",
    "        self.get_graph()\n",
    "        self.compute_stats(step)\n",
    "        pos = layout(self['graph'])\n",
    "        for cd, nodes in self['bgs'].groupby('cd')['geo_id']:\n",
    "            H = self['graph'].subgraph(nodes)\n",
    "            nx.draw_networkx_nodes(H, pos=pos, node_size=10, node_color=self['clr_seq'][cd-1])\n",
    "        nx.draw_networkx_edges(self['graph'], pos=pos)\n",
    "        plt.show()\n",
    "\n",
    "    def check_pop_balance(self, T):\n",
    "        comp = nx.connected_components(T)\n",
    "        next(comp)\n",
    "        s = sum(T.nodes[n]['total_pop'] for n in next(comp))\n",
    "        return abs(s - self.pop_target) <= self.pop_err_max\n",
    "        \n",
    "    def recom_step(self):\n",
    "        self.get_graph()\n",
    "        self['bgs'].set_index('geo_id', inplace=True)\n",
    "        recom_found = False\n",
    "        attempts = 0\n",
    "        for curr in self['rng'].permutation([(a,b) for a in self.cd_names for b in self.cd_names if a < b]).tolist():\n",
    "            nodes = self['bgs'].query(f'cd in {curr}').copy()\n",
    "            H = self['graph'].subgraph(nodes.index)\n",
    "            trees = []\n",
    "            for i in range(1000):\n",
    "                w = {e: self['rng'].uniform() for e in H.edges}\n",
    "                nx.set_edge_attributes(H, w, \"weight\")\n",
    "                T = nx.minimum_spanning_tree(H, \"weight\")\n",
    "                h = hash(tuple(sorted(T.edges)))\n",
    "                if h not in trees:\n",
    "                    trees.append(h)\n",
    "                    for e in self['rng'].permutation(T.edges):\n",
    "                        attempts += 1\n",
    "                        T.remove_edge(*e)\n",
    "                        if self.check_pop_balance(T):\n",
    "                            recom_found = True\n",
    "                            new = [list(c) for c in nx.connected_components(T)]\n",
    "                            nodes['cd_new'] = 0\n",
    "                            for n, c in zip(new, curr):\n",
    "                                nodes.loc[n, 'cd_new'] = c\n",
    "                            i = nodes.groupby(['cd','cd_new'])['area'].sum().idxmax()\n",
    "                            if i[0] != i[1]:\n",
    "                                new[0], new[1] = new[1], new[0]\n",
    "                            for n, c in zip(new, curr):\n",
    "                                self['bgs'].loc[n, 'cd'] = c\n",
    "                            break\n",
    "                        T.add_edge(*e)\n",
    "                else:\n",
    "                    print('Got a repeat spanning tree')\n",
    "                if recom_found:\n",
    "                    break\n",
    "            if recom_found:\n",
    "                break\n",
    "        self['bgs'].reset_index(inplace=True)\n",
    "        assert recom_found, \"No suitable recomb step found\"\n",
    "        return recom_found, attempts, trees\n",
    "        \n",
    "    def record(self, concat=False):\n",
    "        self.compute_stats()\n",
    "        record_cols = {'stats':['step','cd','cd_total_pop','cd_area','cd_polsby','cd_transit'],\n",
    "                       'bgs'  :['step','cd','geo_id']}\n",
    "        for X, cols in record_cols.items():\n",
    "            H = f'{X}_hist'\n",
    "            if concat:\n",
    "                self[H] = self.set_dtypes(pd.concat(self[H], ignore_index=True)[cols])\n",
    "                self[H].to_parquet(self['files']['run'] / f'{X}_hist.parquet', index=False)\n",
    "            else:\n",
    "                df = self.set_dtypes(self[X][cols])\n",
    "                try:\n",
    "                    self[H].append(df)\n",
    "                except:\n",
    "                    self[H] = [df]\n",
    "\n",
    "    def run_mcmc(self, steps=10, update_period=5):\n",
    "        def g(t):\n",
    "            hours, t = divmod(t, 60*60)\n",
    "            minutes, seconds = divmod(t, 60)\n",
    "            return f'{int(hours)}:{int(minutes)}:{seconds:.1f}'\n",
    "        \n",
    "        self.record()\n",
    "        start = time.perf_counter()\n",
    "        for step in range(1, steps+1):\n",
    "            self['bgs']['step'] = step\n",
    "            success, attempts, trees = self.recom_step()\n",
    "            self.record()\n",
    "            if step % update_period == 0:\n",
    "                stop = time.perf_counter()\n",
    "                elapsed = stop - start\n",
    "                total = elapsed / step * steps\n",
    "                remain = total - elapsed\n",
    "                print(f\"I've done {step} steps in {g(elapsed)}; time remaining {g(remain)} (est)\")\n",
    "\n",
    "        self['files']['run'] = self['run_path'] / f'runs/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}'\n",
    "        self['files']['run'].mkdir(parents=True, exist_ok=True)\n",
    "        self.record(concat=True)\n",
    "        self['steps'] = np.unique(self['bgs_hist']['step'])\n",
    "        \n",
    "    def read_prior(self, before_most_recent=0):\n",
    "        path = sorted((g['run_path'] / 'runs').iterdir(), reverse=True)[before_most_recent]\n",
    "        for X in ['bgs_hist', 'stats_hist']:\n",
    "            self[X] = pd.read_parquet(path / f'{X}.parquet')\n",
    "        self['steps'] = np.unique(self['bgs_hist']['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuing-stockholm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Texas'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting bgs - found /home/jupyter/simulations/2017/TX/bgs.parquet\n"
     ]
    }
   ],
   "source": [
    "# Create Gerry object\n",
    "# Looks for local saved copies of bgs, pairs, and graph (fast) unless otherwise specified in overwrite\n",
    "# Anything not found is compiled from source (slow)\n",
    "# clr_seq = color scheme ... see last cell for other options\n",
    "# pop_err_max_pct = maximum allowed departure of any cd from perfect population balance\n",
    "\n",
    "# geo_simplification determines how aggressively the polygons are smoothed - changes will not take effect until existing 'bgs' file is overwritten/deleted\n",
    "# min_graph_degree = smallest allowed number of neighbors for each bg; assigns nearest non-adjacent neighbors if not enough - - changes will not take effect until existing 'graph' file is overwritten/deleted\n",
    "# overwrite = which of 'bgs', 'pairs', and 'graph' to overwrite and recompile from source\n",
    "\n",
    "\n",
    "states = get_states()\n",
    "states\n",
    "for i, state in states.iterrows():\n",
    "    if state['abbr'] == 'TX':\n",
    "        display(state['name'])\n",
    "        g = Gerry(abbr=state['abbr'],\n",
    "                  yr=2017,\n",
    "                  clr_seq=px.colors.qualitative.Antique,\n",
    "                  pop_err_max_pct=0.8,\n",
    "                  geo_simplification=0.003,\n",
    "                  min_graph_degree=1,\n",
    "                  overwrite=[],\n",
    "                  seed=30,\n",
    "                 )\n",
    "    #     g.get_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "third-validity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def lower_cols(df):\n",
    "    df.rename(columns={x:x.lower() for x in df.columns}, inplace=True)\n",
    "    \n",
    "vtds = gpd.read_file(\"/home/jupyter/TX_VTDS/\")\n",
    "lower_cols(vtds)\n",
    "\n",
    "blocks = gpd.read_file(\"/home/jupyter/TX_blocks/\", rows=10)\n",
    "lower_cols(blocks)\n",
    "blocks.rename(columns={'geoid20': 'geo_id'}, inplace=True)\n",
    "\n",
    "A = vtds[['cntyvtd','geometry']].set_index('cntyvtd').to_crs(crs_map)\n",
    "A['area'] = A.area\n",
    "B = blocks[['geo_id', 'geometry']].set_index('geo_id').to_crs(crs_map)\n",
    "B['area'] = B.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dressed-mentor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statefp20</th>\n",
       "      <th>countyfp20</th>\n",
       "      <th>tractce20</th>\n",
       "      <th>blockce20</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>name20</th>\n",
       "      <th>mtfcc20</th>\n",
       "      <th>ur20</th>\n",
       "      <th>uace20</th>\n",
       "      <th>uatype20</th>\n",
       "      <th>funcstat20</th>\n",
       "      <th>aland20</th>\n",
       "      <th>awater20</th>\n",
       "      <th>intptlat20</th>\n",
       "      <th>intptlon20</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>061</td>\n",
       "      <td>013802</td>\n",
       "      <td>2005</td>\n",
       "      <td>480610138022005</td>\n",
       "      <td>Block 2005</td>\n",
       "      <td>G5040</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>8679</td>\n",
       "      <td>0</td>\n",
       "      <td>+25.9043452</td>\n",
       "      <td>-097.4861134</td>\n",
       "      <td>POLYGON ((-97.48676 25.90436, -97.48609 25.904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>061</td>\n",
       "      <td>010301</td>\n",
       "      <td>1035</td>\n",
       "      <td>480610103011035</td>\n",
       "      <td>Block 1035</td>\n",
       "      <td>G5040</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>180923</td>\n",
       "      <td>0</td>\n",
       "      <td>+26.2516604</td>\n",
       "      <td>-097.8192804</td>\n",
       "      <td>POLYGON ((-97.82109 26.25476, -97.81942 26.253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>061</td>\n",
       "      <td>012104</td>\n",
       "      <td>3008</td>\n",
       "      <td>480610121043008</td>\n",
       "      <td>Block 3008</td>\n",
       "      <td>G5040</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>277322</td>\n",
       "      <td>0</td>\n",
       "      <td>+26.1247970</td>\n",
       "      <td>-097.6926397</td>\n",
       "      <td>POLYGON ((-97.69613 26.12368, -97.69287 26.127...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statefp20 countyfp20 tractce20 blockce20           geo_id      name20  \\\n",
       "0        48        061    013802      2005  480610138022005  Block 2005   \n",
       "1        48        061    010301      1035  480610103011035  Block 1035   \n",
       "2        48        061    012104      3008  480610121043008  Block 3008   \n",
       "\n",
       "  mtfcc20  ur20 uace20 uatype20 funcstat20  aland20  awater20   intptlat20  \\\n",
       "0   G5040  None   None     None          S     8679         0  +25.9043452   \n",
       "1   G5040  None   None     None          S   180923         0  +26.2516604   \n",
       "2   G5040  None   None     None          S   277322         0  +26.1247970   \n",
       "\n",
       "     intptlon20                                           geometry  \n",
       "0  -097.4861134  POLYGON ((-97.48676 25.90436, -97.48609 25.904...  \n",
       "1  -097.8192804  POLYGON ((-97.82109 26.25476, -97.81942 26.253...  \n",
       "2  -097.6926397  POLYGON ((-97.69613 26.12368, -97.69287 26.127...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "binding-component",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def f(b):\n",
    "    C = A.intersection(b['geometry']).area\n",
    "    C /= b['area']\n",
    "    mask = C > 1e-2\n",
    "    return C[mask]\n",
    "\n",
    "d = {geo_id:f(b) for geo_id, b in B.iterrows()}\n",
    "I = pd.concat(d).reset_index()\n",
    "I.columns = ['geo_id', 'cntyvtd', 'area']\n",
    "I.to_parquet('/home/jupyter/bg_vtd_proportions.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blocked-caribbean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>cntyvtd</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480610138022005</td>\n",
       "      <td>610006</td>\n",
       "      <td>0.981346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480610138022005</td>\n",
       "      <td>610037</td>\n",
       "      <td>0.018654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>480610103011035</td>\n",
       "      <td>610027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480610121043008</td>\n",
       "      <td>610022</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481659501002028</td>\n",
       "      <td>1650007</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>482479504001259</td>\n",
       "      <td>2470004</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>482479504001086</td>\n",
       "      <td>2470003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>484530330002016</td>\n",
       "      <td>4530349</td>\n",
       "      <td>0.140496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>484530330002016</td>\n",
       "      <td>4530365</td>\n",
       "      <td>0.859504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>484530346001000</td>\n",
       "      <td>4530334</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>484790017094012</td>\n",
       "      <td>4790341</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>484790001012044</td>\n",
       "      <td>4790124</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_id  cntyvtd      area\n",
       "0   480610138022005   610006  0.981346\n",
       "1   480610138022005   610037  0.018654\n",
       "2   480610103011035   610027  1.000000\n",
       "3   480610121043008   610022  1.000000\n",
       "4   481659501002028  1650007  1.000000\n",
       "5   482479504001259  2470004  1.000000\n",
       "6   482479504001086  2470003  1.000000\n",
       "7   484530330002016  4530349  0.140496\n",
       "8   484530330002016  4530365  0.859504\n",
       "9   484530346001000  4530334  1.000000\n",
       "10  484790017094012  4790341  1.000000\n",
       "11  484790001012044  4790124  1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.draw_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run recom MCMC for specified number of steps, reporting progress every \"update_period\" steps\n",
    "# results save to timestamped file in /home/jupyter/simulations/yr/state/runs\n",
    "steps = 4\n",
    "g.run_mcmc(steps=steps, update_period=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read saved MCMC runs\n",
    "# \"before_most_recent\" = how far back to go .. 0=most recent run, 1=run before that, 2=run before that, ...\n",
    "g.read_prior(before_most_recent=0)\n",
    "for step in g['steps'][::1]:\n",
    "    g.draw_map(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.colors.qualitative.swatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-central",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
