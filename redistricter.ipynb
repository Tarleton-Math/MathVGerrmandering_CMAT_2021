{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7555a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jupyter/MathVGerrmandering_CMAT_2021\n",
      "Get crosswalks_TX_2010_tabblock   ... tabblock table exists ... success\n",
      "Get assignments_TX_2020_tabblock  ... tabblock table exists ... success\n",
      "Get shapes_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get census_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get elections_TX_2020_tabblock    ... tabblock table exists ... success\n",
      "Get nodes_TX_2020_cntyvtd_cd      ... cntyvtd table exists ... success\n",
      "Get graph_TX_2020_cntyvtd         ... gpickle exists ... success\n",
      "hashseed != 0 so results are NOT reproducible and will NOT be saved to BigQuery\n",
      "starting seed 10000starting seed 10001\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cmat-315920.results_TX_2020_cntyvtd_cd.10001_plans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\", line 132, in f\n    M.run_chain()\n  File \"/home/jupyter/MathVGerrmandering_CMAT_2021/src/mcmc.py\", line 119, in run_chain\n    self.save_results(gcs=True)\n  File \"/home/jupyter/MathVGerrmandering_CMAT_2021/src/mcmc.py\", line 158, in save_results\n    to_gcs(tbl)\n  File \"/home/jupyter/MathVGerrmandering_CMAT_2021/src/__init__.py\", line 40, in to_gcs\n    gcs_bucket.blob(str(file).replace(str(root_path)+'/', '')).upload_from_filename(file)\n  File \"/opt/conda/lib/python3.7/site-packages/google/cloud/storage/blob.py\", line 2627, in upload_from_filename\n    with open(filename, \"rb\") as file_obj:\nFileNotFoundError: [Errno 2] No such file or directory: 'cmat-315920.results_TX_2020_cntyvtd_cd.10001_plans'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_opts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'workers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m#     print(f'I will run seeds {seeds}', flush=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m# from src.analysis import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmcmc_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'finished seed {seed} with pop_imbalance={M.pop_imbalance:.1f} after {M.step} steps and {time_formatter(time.time() - start)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/src/mcmc.py\u001b[0m in \u001b[0;36mrun_chain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;31m#         print('MCMC done')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/src/mcmc.py\u001b[0m in \u001b[0;36msave_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtbls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mto_gcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/src/__init__.py\u001b[0m in \u001b[0;36mto_gcs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_gcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgcs_bucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mupload_from_filename\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_content_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2627\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mtotal_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             self.upload_from_file(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cmat-315920.results_TX_2020_cntyvtd_cd.10001_plans'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "%run -i redistricter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "ds = f'{proj_id}.TX_2020_cntyvtd_cd'\n",
    "for src_tbl in bqclient.list_tables(ds, max_):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.list_tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3684d0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1da14165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying cmat-315920:results.TX_2020_cntyvtd_cd_0001_plans to cmat-315920.TX_2020_cntyvtd_cd.0001_plans\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# #     src = f'{ds}.{src}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'copying {src_tbl.full_table_id} to {dest}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#     try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         bqclient.get_table(dest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src import *\n",
    "for src_tbl in bqclient.list_tables(f'{proj_id}.results'):\n",
    "    w = src_tbl.table_id.split('_')\n",
    "    ds = f'{proj_id}.{\"_\".join(w[:4])}'\n",
    "    dest = f'{ds}.{\"_\".join(w[4:])}'\n",
    "    try:\n",
    "        bqclient.get_table(dest)\n",
    "    except:\n",
    "        print(f'copying {src_tbl.full_table_id} to {dest}')\n",
    "        bqclient.create_dataset(ds, exists_ok=True)\n",
    "        bqclient.copy_table(src_tbl, dest).result()\n",
    "    \n",
    "#     print(src_tbl.table_id, dest_tbl)\n",
    "#     bqclient.copy_table(src_tbl, dest_tbl).result()\n",
    "#     client.delete_table(table_id, not_found_ok=True)\n",
    "#     print(ds)\n",
    "# bqclient.list_tables?\n",
    "# (root)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37ec44d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bqclient.get_table('cmat-315920.TX_2020_cntyvtd_cd.10001_plans')\n",
    "except:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174729ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting states\n"
     ]
    }
   ],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634fe11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'cmat-315920.results.TX_2020_cntyvtd_cd_0000_plans'\n",
    "check_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8a133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13efcc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'FilePathOrBuffer | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'snappy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpartition_cols\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstorage_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'StorageOptions'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'bytes | None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Write a DataFrame to the binary parquet format.\n",
       "\n",
       "This function writes the dataframe as a `parquet file\n",
       "<https://parquet.apache.org/>`_. You can choose different parquet\n",
       "backends, and have the option of compression. See\n",
       ":ref:`the user guide <io.parquet>` for more details.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path : str or file-like object, default None\n",
       "    If a string, it will be used as Root Directory path\n",
       "    when writing a partitioned dataset. By file-like object,\n",
       "    we refer to objects with a write() method, such as a file handle\n",
       "    (e.g. via builtin open function) or io.BytesIO. The engine\n",
       "    fastparquet does not accept file-like objects. If path is None,\n",
       "    a bytes object is returned.\n",
       "\n",
       "    .. versionchanged:: 1.2.0\n",
       "\n",
       "    Previously this was \"fname\"\n",
       "\n",
       "engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
       "    Parquet library to use. If 'auto', then the option\n",
       "    ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
       "    behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
       "    'pyarrow' is unavailable.\n",
       "compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
       "    Name of the compression to use. Use ``None`` for no compression.\n",
       "index : bool, default None\n",
       "    If ``True``, include the dataframe's index(es) in the file output.\n",
       "    If ``False``, they will not be written to the file.\n",
       "    If ``None``, similar to ``True`` the dataframe's index(es)\n",
       "    will be saved. However, instead of being saved as values,\n",
       "    the RangeIndex will be stored as a range in the metadata so it\n",
       "    doesn't require much space and is faster. Other indexes will\n",
       "    be included as columns in the file output.\n",
       "partition_cols : list, optional, default None\n",
       "    Column names by which to partition the dataset.\n",
       "    Columns are partitioned in the order they are given.\n",
       "    Must be None if path is not a string.\n",
       "storage_options : dict, optional\n",
       "    Extra options that make sense for a particular storage connection, e.g.\n",
       "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
       "    are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
       "    starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
       "    ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
       "\n",
       "    .. versionadded:: 1.2.0\n",
       "\n",
       "**kwargs\n",
       "    Additional arguments passed to the parquet library. See\n",
       "    :ref:`pandas io <io.parquet>` for more details.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "bytes if no path argument is provided else None\n",
       "\n",
       "See Also\n",
       "--------\n",
       "read_parquet : Read a parquet file.\n",
       "DataFrame.to_csv : Write a csv file.\n",
       "DataFrame.to_sql : Write to a sql table.\n",
       "DataFrame.to_hdf : Write to hdf.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This function requires either the `fastparquet\n",
       "<https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
       "<https://arrow.apache.org/docs/python/>`_ library.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
       ">>> df.to_parquet('df.parquet.gzip',\n",
       "...               compression='gzip')  # doctest: +SKIP\n",
       ">>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4\n",
       "\n",
       "If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
       "object, as long as you don't use partition_cols, which creates multiple files.\n",
       "\n",
       ">>> import io\n",
       ">>> f = io.BytesIO()\n",
       ">>> df.to_parquet(f)\n",
       ">>> f.seek(0)\n",
       "0\n",
       ">>> content = f.read()\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.to_parquet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16cff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtractJobConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Configuration options for extract jobs.\n",
       "\n",
       "All properties in this class are optional. Values which are :data:`None` ->\n",
       "server defaults. Set properties on the constructed configuration by using\n",
       "the property name as the name of a keyword argument.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job/extract.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src import *\n",
    "google.cloud.bigquery.job.ExtractJobConfig(destinationFormat='parquet', compression='SNAPPY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62e46ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wab</td>\n",
       "      <td>wa</td>\n",
       "      <td>b</td>\n",
       "      <td>wab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wa1</td>\n",
       "      <td>wa</td>\n",
       "      <td>01</td>\n",
       "      <td>wa01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wb2</td>\n",
       "      <td>wb</td>\n",
       "      <td>02</td>\n",
       "      <td>wb02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w12</td>\n",
       "      <td>w1</td>\n",
       "      <td>2</td>\n",
       "      <td>w12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a   b   c     d\n",
       "0  wab  wa   b   wab\n",
       "1  wa1  wa  01  wa01\n",
       "2  wb2  wb  02  wb02\n",
       "3  w12  w1   2   w12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['a'] = ['wab', 'wa1', 'wb2', 'w12']\n",
    "df['b'] = df['a'].str[:-1]\n",
    "df['c'] = df['a'].str[-1]\n",
    "mask = ~df['b'].str[-1].str.isnumeric() & df['c'].str.isnumeric()\n",
    "df.loc[mask, 'c'] = df.loc[mask, 'c'].str.rjust(2, '0')\n",
    "df['d'] = df['b'] + df['c']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pathlib.Path('/home/jupyter/redistricting_data/crosswalks/TX')\n",
    "# f.mkdir()\n",
    "str(f)\n",
    "\n",
    "gcsclient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(G.crosswalks.pq).replace(str(root_loc), 'gs://bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d8ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6393bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.crosswalks.zip\n",
    "\n",
    "\n",
    "# pq.with_suffix('.temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data_gcs)\n",
    "data_gcs.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a70202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_table(G.crosswalks.tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7421ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(root_loc / 'temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d3367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet(root_loc / 'temp.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a057c49",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba98e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_gcs + G.crosswalks.pq.name\n",
    "df2.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd98a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gcs = f'gs://redistricting_data/'\n",
    "f = data_gcs + G.crosswalks.pq.name\n",
    "f\n",
    "bqclient.extract_table(G.crosswalks.tbl, data_gcs + G.crosswalks.pq.name).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.extract_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = root_loc / 'crosswalks_TX_2010.parquet'\n",
    "f\n",
    "df = pd.read_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb4d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'gs://'+b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "df = pd.DataFrame()\n",
    "# df.to_parquet(b.blob('test'))\n",
    "\n",
    "t = b.blob('test/test2')\n",
    "# df.to_parquet(t)\n",
    "# t.path\n",
    "# g://t.name\n",
    "dir(t)\n",
    "# t._get_download_url(gcsclient)\n",
    "\n",
    "# t.__name__\n",
    "# t.path_helper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "c = b.blob('test')\n",
    "c.upload_from_filenameid(root_loc / 'git.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72738d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_id = 'cmat-315920'\n",
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "# root_gcs.get_blob\n",
    "\n",
    "b = root_gcs.blob('redistricting_data/hi2.txt')#.upload_from_string('hello world')\n",
    "\n",
    "\n",
    "b.blob('sub')\n",
    "# gcsclient.create_bucket?\n",
    "\n",
    "\n",
    "# get_bucket(f'{proj_id}-bucket')\n",
    "# data_gcs = root_gcs.get_blob('redistricting_data/hi.txt')\n",
    "# data_gcs.upload_from_string('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4811a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud, pandas as pd\n",
    "cred, proj = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "\n",
    "proj_id = 'cmat-315920'\n",
    "user_name = 'cook'\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bqclient   = google.cloud.bigquery.Client(credentials=cred, project=proj)\n",
    "bqdata     = bqclient.get_dataset(f'redistricting_data')\n",
    "bqresults  = bqclient.get_dataset(f'redistricting_results_{user_name}')\n",
    "\n",
    "L = [x for x in bqclient.list_tables(bqdata)]\n",
    "dir(L[0])\n",
    "t = L[0]\n",
    "t.table_id\n",
    "bqdata.\n",
    "\n",
    "\n",
    "# gcsclient  = google.cloud.storage.Client(credentials=cred, project=proj)\n",
    "# gcsresults = gcsclient.get_bucket(f'redistricting_results')\n",
    "\n",
    "# gcsclient.create_bucket('redistricting_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4699509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bqproj = \n",
    "list(bqclient.list_datasets())\n",
    "bqclient.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23092247",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient   = bigquery.Client(credentials=cred, project=proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsclient = google.cloud.storage.Client(project=proj_id)\n",
    "list(gcsclient.list_buckets())\n",
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "folder = gcsbucket.blob('test')\n",
    "gcsbucket.exists()\n",
    "folder.exists()\n",
    "gcsbucket.blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c105ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "list(gcsbucket.list_blobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab398323",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "data_gcs = root_gcs.get_blob('redistricting_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce488815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(Base):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bq_results\n",
    "gcs_results\n",
    "\n",
    "\n",
    "results_stem = f'{G.gpickle.stem[6:]}/{timestamp}'\n",
    "\n",
    "results_loc = root_path / f'results/{results_stem}'\n",
    "results_gcs = f'gc://{proj_id}-bucket/results/{results_stem}'\n",
    "results_bq  = f'{proj_id}.{results_stem}'\n",
    "\n",
    "results_loc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gcsclient = storage.Client(project=proj_id)\n",
    "\n",
    "gcsbucket = gcsclient.get_bucket('buckets')\n",
    "blob = bucket.blob('some/folder/name/')\n",
    "bqclient.create_dataset(results_bq, exists_ok=True)\n",
    "results_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9287997",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdad955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "nodes_tbl = f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "mcmc_tbl  = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_seed_0000'\n",
    "seeds = np.arange(16)\n",
    "A = Analysis(nodes=nodes_tbl, mcmc=mcmc_tbl, seeds=seeds)\n",
    "A.tbl = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "A.fetch_results()\n",
    "A.save_results()\n",
    "# A.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(A)\n",
    "'_'.join(G.gpickle.stem.split('_')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e78f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.tbl.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc4785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48324c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.to_parquet(f\"gs://{proj_id}-bucket/{A.tbl.split('.')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa268b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a54d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=A\n",
    "A.tbl\n",
    "root_path / f'results/{self.tbl.split(\".\")[-1]}.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9479d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "idx = ['seed', 'plan', 'cd']\n",
    "for col in idx:\n",
    "    df[col] = rjust(df[col])\n",
    "df.sort_values(idx, inplace=True)\n",
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "file.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(file, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d19b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40393da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    B.pop_imbalance,\n",
    "    B.polsby_popper as polsby_popper_plan,\n",
    "    C.polsby_popper as polsby_popper_district,\n",
    "    C.total_pop\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a94313",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "nodes = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    E.seed,\n",
    "    E.plan,\n",
    "    E.{district_type},\n",
    "    max(E.pop_imbalance) as pop_imbalance,\n",
    "    max(E.polsby_popper_plan) as polsby_popper_plan,\n",
    "    max(E.polsby_popper_district) as polsby_popper_district,\n",
    "    max(E.total_pop) as total_pop,\n",
    "    sum(F.total_1race)\n",
    "from (\n",
    "    select\n",
    "        B.seed,\n",
    "        B.plan,\n",
    "        C.{district_type},\n",
    "        B.pop_imbalance,\n",
    "        B.polsby_popper as polsby_popper_plan,\n",
    "        C.polsby_popper as polsby_popper_district,\n",
    "        C.total_pop,\n",
    "        D.geoid\n",
    "    from (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            select\n",
    "                *,\n",
    "                row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "            from (\n",
    "                {summary_stack}\n",
    "                ) as A\n",
    "            )\n",
    "        where r = 1\n",
    "        ) as B\n",
    "    inner join (\n",
    "        {stats_stack}\n",
    "        ) as C\n",
    "    on\n",
    "        B.seed = C.seed and B.plan = C.plan\n",
    "    inner join (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            {plans_stack}\n",
    "            )\n",
    "        ) as D\n",
    "    on\n",
    "        C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "    ) as E\n",
    "inner join\n",
    "    {nodes} as F\n",
    "on\n",
    "    E.geoid = F.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "G.nodes_tbl = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "M.tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "cols = [c for c in get_cols(self.nodes) if c not in Levels + District_types + ['geoid', 'county', 'total_pop', 'polygon', 'perim', 'polsby_popper', 'density', 'point']]\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    max(B.pop_imbalance) as pop_imbalance_plan,\n",
    "    max(B.polsby_popper) as polsby_popper_plan,\n",
    "    max(C.polsby_popper) as polsby_popper_district,\n",
    "    max(C.total_pop) as total_pop,\n",
    "    max(C.total_pop) / sum(E.aland) as density,\n",
    "    {join_str(1).join([f'sum(E.{c}) as {c}' for c in cols])}\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "inner join (\n",
    "    {stats_stack}\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "inner join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {plans_stack}\n",
    "        )\n",
    "    ) as D\n",
    "on\n",
    "    C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "inner join\n",
    "    {nodes} as E\n",
    "on\n",
    "    D.geoid = E.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea57084",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "df = pd.read_csv(file+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "pq = file /'.parquet'\n",
    "pq.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(pq, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "\"\"\"\n",
    "run_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "sels = [f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in range (100, 116) if seed != 110]\n",
    "query = \"\\nunion all\\n\".join(sels)\n",
    "query = f\"\"\"\n",
    "    select\n",
    "        A.hash,\n",
    "        max(seed),\n",
    "        max(plan),\n",
    "        count(*) as count\n",
    "    from (\n",
    "        {query}\n",
    "        ) as A\n",
    "    group by\n",
    "        A.hash\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed634fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['seed'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab46c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
