{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684afc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jupyter/MathVGerrmandering_CMAT_2021\n",
      "Get crosswalks_TX_2010_tabblock   ... tabblock table exists ... success\n",
      "Get assignments_TX_2020_tabblock  ... tabblock table exists ... success\n",
      "Get shapes_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get census_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get elections_TX_2020_tabblock    ... tabblock table exists ... success\n",
      "Get nodes_TX_2020_cntyvtd_cd      ... cntyvtd table exists ... success\n",
      "Get graph_TX_2020_cntyvtd_cd      ... gpickle exists ... success\n",
      "hashseed != 0 so results are NOT reproducible and will NOT be saved to BigQuery\n",
      "stacking hashes into batches\n",
      "running step 0\n",
      "running step 1\n",
      "running step 2\n",
      "running step 3\n",
      "running step 4\n",
      "running step 5\n",
      "running step 6\n",
      "running step 7\n",
      "running step 8\n",
      "running step 9\n",
      "running step 10\n",
      "running step 11\n",
      "running step 12\n",
      "running step 13\n",
      "running step 14\n",
      "running step 15\n",
      "running step 16\n",
      "running step 17\n",
      "running step 18\n",
      "running step 19\n",
      "running step 20\n",
      "stacking hash batches\n",
      "joining tables in batches\n",
      "running step 0\n",
      "running step 1\n",
      "running step 2\n",
      "running step 3\n",
      "running step 4\n",
      "running step 5\n",
      "running step 6\n",
      "running step 7\n",
      "running step 8\n",
      "running step 9\n",
      "running step 10\n",
      "running step 11\n",
      "running step 12\n",
      "running step 13\n",
      "running step 14\n",
      "running step 15\n",
      "running step 16\n",
      "running step 17\n",
      "running step 18\n",
      "running step 19\n",
      "running step 20\n",
      "stacking joined table batches\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Analysis' object has no attribute 'tbl_hash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_tbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, batch_size=2, max_results=20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'analysis took {time_formatter(time.time() - start)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/src/analysis.py\u001b[0m in \u001b[0;36mcompute_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mload_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mdelete_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbl_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mdelete_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbl_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Analysis' object has no attribute 'tbl_hash'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "graph_opts = {\n",
    "    'abbr'             : 'TX',\n",
    "    'level'            : 'cntyvtd',\n",
    "    'district_type'    : 'cd',\n",
    "    'census_yr'        : 2020,\n",
    "    'county_line'      : False,\n",
    "}\n",
    "%run -i redistricter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d3d587a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmat-315920.TX_2020_cntyvtd_cd.TX_2020_cntyvtd_cd_0000000_allresults'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_tableA.tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(M.graph.nodes(data='plan'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=M\n",
    "df = self.splits\n",
    "(df['whole_districts_target'] - df['whole_districts']).abs().sum()\n",
    "(df['county_parts_target'] - df['county_parts']).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c5eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=G\n",
    "# w = dict(self.graph.nodes(data='total_pop'))\n",
    "# sorted(w.items(), key=lambda x:x[1], reverse=True)\n",
    "# w = dict(self.graph.nodes(data='total_pop'))\n",
    "sorted(self.graph.nodes(data='total_pop'), key=lambda x:x[1], reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449baa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d['total_pop'] for n, d in G.graph.nodes(data=True)) / 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_districts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b71c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8be807",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = G\n",
    "df = read_table(G.nodes.tbl)\n",
    "idx = df.nlargest(2, 'total_pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.copy()\n",
    "m = n[self.district_type].max()\n",
    "n.loc[idx.index[0], self.district_type] = m+1\n",
    "n.loc[idx.index[1], self.district_type] = m+2\n",
    "m = n[self.district_type].max()\n",
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "(d.max() - d.min()) / pop_ideal * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b62509",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.copy()\n",
    "m = n[self.district_type].max()\n",
    "n.loc[idx.index[0], self.district_type] = m+1\n",
    "n.loc[idx.index[1], self.district_type] = m+2\n",
    "m = n[self.district_type].max()\n",
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "(d.max() - d.min()) / pop_ideal * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb07eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "d\n",
    "# (d.max() - d.min()) / pop_ideal\n",
    "(d.max() - d.min()) / pop_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e99564",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.graph.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.DataFrame.from_dict(dict(self.graph.nodes(data=True)), orient='index')\n",
    "\n",
    "ideal_pop = round(n['total_pop'].sum() / 38)\n",
    "n['target'] = n.groupby('county')['total_pop'].transform('sum') / ideal_pop\n",
    "n['whole_districts_target'] = np.floor(n['target']).astype(int)\n",
    "n['parts_target'] = np.ceil(n['target']).astype(int)\n",
    "\n",
    "\n",
    "w = n[['county', self.district_type, 'parts_target', 'whole_districts_target']].drop_duplicates()\n",
    "w['whole_district'] = w.groupby(self.district_type)['county'].transform('count') <= 1\n",
    "w['whole_districts'] = w.groupby('county')['whole_district'].transform('sum')\n",
    "w['county_parts'] = w.groupby('county')[self.district_type].transform('count')\n",
    "w.drop(columns=[self.district_type, 'whole_district']).drop_duplicates()\n",
    "# w['parts_error'] = (w['parts_target'] - w['parts']).abs()\n",
    "# w['districts_contained_error'] = (w['districts_contained_target'] - w['districts_contained']).abs()\n",
    "# w.sort_values('parts_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict(self.graph.nodes(data=True)), orient='index').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2495bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.graph.nodes(data=True))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae992a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b5ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f'{root_path}/results/TX_2020_cntyvtd_cd/TX_2020_cntyvtd_cd_0000000_allresults'\n",
    "pq  = file + '.parquet'\n",
    "csv = file + '.csv'\n",
    "df = pd.read_parquet(pq)\n",
    "df.to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23356c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "w = 'TX_2020_cntyvtd_cd'\n",
    "bq = f'{proj_id}.w'\n",
    "\n",
    "for tbl in bqclient.list_tables(w):\n",
    "    a = tbl.full_table_id.replace(':','.')\n",
    "    if a.find('allresults') >= 0:\n",
    "        print(f'deleting {a}')\n",
    "        delete_table(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cols(f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd')[301:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "ds = f'{proj_id}.TX_2020_cntyvtd_cd'\n",
    "for src_tbl in bqclient.list_tables(ds, max_):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b796e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.list_tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d18b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "for src_tbl in bqclient.list_tables(f'{proj_id}.results'):\n",
    "    w = src_tbl.table_id.split('_')\n",
    "    ds = f'{proj_id}.{\"_\".join(w[:4])}'\n",
    "    dest = f'{ds}.{\"_\".join(w[4:])}'\n",
    "    try:\n",
    "        bqclient.get_table(dest)\n",
    "    except:\n",
    "        print(f'copying {src_tbl.full_table_id} to {dest}')\n",
    "        bqclient.create_dataset(ds, exists_ok=True)\n",
    "        bqclient.copy_table(src_tbl, dest).result()\n",
    "    \n",
    "#     print(src_tbl.table_id, dest_tbl)\n",
    "#     bqclient.copy_table(src_tbl, dest_tbl).result()\n",
    "#     client.delete_table(table_id, not_found_ok=True)\n",
    "#     print(ds)\n",
    "# bqclient.list_tables?\n",
    "# (root)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bqclient.get_table('cmat-315920.TX_2020_cntyvtd_cd.10001_plans')\n",
    "except:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9475ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'cmat-315920.results.TX_2020_cntyvtd_cd_0000_plans'\n",
    "check_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea74189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "google.cloud.bigquery.job.ExtractJobConfig(destinationFormat='parquet', compression='SNAPPY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24169402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['a'] = ['wab', 'wa1', 'wb2', 'w12']\n",
    "df['b'] = df['a'].str[:-1]\n",
    "df['c'] = df['a'].str[-1]\n",
    "mask = ~df['b'].str[-1].str.isnumeric() & df['c'].str.isnumeric()\n",
    "df.loc[mask, 'c'] = df.loc[mask, 'c'].str.rjust(2, '0')\n",
    "df['d'] = df['b'] + df['c']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pathlib.Path('/home/jupyter/redistricting_data/crosswalks/TX')\n",
    "# f.mkdir()\n",
    "str(f)\n",
    "\n",
    "gcsclient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ebb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(G.crosswalks.pq).replace(str(root_loc), 'gs://bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3bba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.crosswalks.zip\n",
    "\n",
    "\n",
    "# pq.with_suffix('.temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data_gcs)\n",
    "data_gcs.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_table(G.crosswalks.tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(root_loc / 'temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f3aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70416bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet(root_loc / 'temp.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae52ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc0f0f",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_gcs + G.crosswalks.pq.name\n",
    "df2.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24daee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gcs = f'gs://redistricting_data/'\n",
    "f = data_gcs + G.crosswalks.pq.name\n",
    "f\n",
    "bqclient.extract_table(G.crosswalks.tbl, data_gcs + G.crosswalks.pq.name).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.extract_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = root_loc / 'crosswalks_TX_2010.parquet'\n",
    "f\n",
    "df = pd.read_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'gs://'+b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "df = pd.DataFrame()\n",
    "# df.to_parquet(b.blob('test'))\n",
    "\n",
    "t = b.blob('test/test2')\n",
    "# df.to_parquet(t)\n",
    "# t.path\n",
    "# g://t.name\n",
    "dir(t)\n",
    "# t._get_download_url(gcsclient)\n",
    "\n",
    "# t.__name__\n",
    "# t.path_helper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "c = b.blob('test')\n",
    "c.upload_from_filenameid(root_loc / 'git.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082cf2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_id = 'cmat-315920'\n",
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "# root_gcs.get_blob\n",
    "\n",
    "b = root_gcs.blob('redistricting_data/hi2.txt')#.upload_from_string('hello world')\n",
    "\n",
    "\n",
    "b.blob('sub')\n",
    "# gcsclient.create_bucket?\n",
    "\n",
    "\n",
    "# get_bucket(f'{proj_id}-bucket')\n",
    "# data_gcs = root_gcs.get_blob('redistricting_data/hi.txt')\n",
    "# data_gcs.upload_from_string('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud, pandas as pd\n",
    "cred, proj = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "\n",
    "proj_id = 'cmat-315920'\n",
    "user_name = 'cook'\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bqclient   = google.cloud.bigquery.Client(credentials=cred, project=proj)\n",
    "bqdata     = bqclient.get_dataset(f'redistricting_data')\n",
    "bqresults  = bqclient.get_dataset(f'redistricting_results_{user_name}')\n",
    "\n",
    "L = [x for x in bqclient.list_tables(bqdata)]\n",
    "dir(L[0])\n",
    "t = L[0]\n",
    "t.table_id\n",
    "bqdata.\n",
    "\n",
    "\n",
    "# gcsclient  = google.cloud.storage.Client(credentials=cred, project=proj)\n",
    "# gcsresults = gcsclient.get_bucket(f'redistricting_results')\n",
    "\n",
    "# gcsclient.create_bucket('redistricting_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ccb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bqproj = \n",
    "list(bqclient.list_datasets())\n",
    "bqclient.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient   = bigquery.Client(credentials=cred, project=proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsclient = google.cloud.storage.Client(project=proj_id)\n",
    "list(gcsclient.list_buckets())\n",
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "folder = gcsbucket.blob('test')\n",
    "gcsbucket.exists()\n",
    "folder.exists()\n",
    "gcsbucket.blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "list(gcsbucket.list_blobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb642fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "data_gcs = root_gcs.get_blob('redistricting_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5be77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(Base):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bq_results\n",
    "gcs_results\n",
    "\n",
    "\n",
    "results_stem = f'{G.gpickle.stem[6:]}/{timestamp}'\n",
    "\n",
    "results_loc = root_path / f'results/{results_stem}'\n",
    "results_gcs = f'gc://{proj_id}-bucket/results/{results_stem}'\n",
    "results_bq  = f'{proj_id}.{results_stem}'\n",
    "\n",
    "results_loc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gcsclient = storage.Client(project=proj_id)\n",
    "\n",
    "gcsbucket = gcsclient.get_bucket('buckets')\n",
    "blob = bucket.blob('some/folder/name/')\n",
    "bqclient.create_dataset(results_bq, exists_ok=True)\n",
    "results_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b95304",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c907792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe93359",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "nodes_tbl = f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "mcmc_tbl  = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_seed_0000'\n",
    "seeds = np.arange(16)\n",
    "A = Analysis(nodes=nodes_tbl, mcmc=mcmc_tbl, seeds=seeds)\n",
    "A.tbl = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "A.fetch_results()\n",
    "A.save_results()\n",
    "# A.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(A)\n",
    "'_'.join(G.gpickle.stem.split('_')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb37444",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.tbl.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62972a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.to_parquet(f\"gs://{proj_id}-bucket/{A.tbl.split('.')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74532109",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=A\n",
    "A.tbl\n",
    "root_path / f'results/{self.tbl.split(\".\")[-1]}.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "idx = ['seed', 'plan', 'cd']\n",
    "for col in idx:\n",
    "    df[col] = rjust(df[col])\n",
    "df.sort_values(idx, inplace=True)\n",
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "file.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(file, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ca7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    B.pop_imbalance,\n",
    "    B.polsby_popper as polsby_popper_plan,\n",
    "    C.polsby_popper as polsby_popper_district,\n",
    "    C.total_pop\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "nodes = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    E.seed,\n",
    "    E.plan,\n",
    "    E.{district_type},\n",
    "    max(E.pop_imbalance) as pop_imbalance,\n",
    "    max(E.polsby_popper_plan) as polsby_popper_plan,\n",
    "    max(E.polsby_popper_district) as polsby_popper_district,\n",
    "    max(E.total_pop) as total_pop,\n",
    "    sum(F.total_1race)\n",
    "from (\n",
    "    select\n",
    "        B.seed,\n",
    "        B.plan,\n",
    "        C.{district_type},\n",
    "        B.pop_imbalance,\n",
    "        B.polsby_popper as polsby_popper_plan,\n",
    "        C.polsby_popper as polsby_popper_district,\n",
    "        C.total_pop,\n",
    "        D.geoid\n",
    "    from (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            select\n",
    "                *,\n",
    "                row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "            from (\n",
    "                {summary_stack}\n",
    "                ) as A\n",
    "            )\n",
    "        where r = 1\n",
    "        ) as B\n",
    "    inner join (\n",
    "        {stats_stack}\n",
    "        ) as C\n",
    "    on\n",
    "        B.seed = C.seed and B.plan = C.plan\n",
    "    inner join (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            {plans_stack}\n",
    "            )\n",
    "        ) as D\n",
    "    on\n",
    "        C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "    ) as E\n",
    "inner join\n",
    "    {nodes} as F\n",
    "on\n",
    "    E.geoid = F.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe68f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "G.nodes_tbl = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "M.tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "cols = [c for c in get_cols(self.nodes) if c not in Levels + District_types + ['geoid', 'county', 'total_pop', 'polygon', 'perim', 'polsby_popper', 'density', 'point']]\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    max(B.pop_imbalance) as pop_imbalance_plan,\n",
    "    max(B.polsby_popper) as polsby_popper_plan,\n",
    "    max(C.polsby_popper) as polsby_popper_district,\n",
    "    max(C.total_pop) as total_pop,\n",
    "    max(C.total_pop) / sum(E.aland) as density,\n",
    "    {join_str(1).join([f'sum(E.{c}) as {c}' for c in cols])}\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "inner join (\n",
    "    {stats_stack}\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "inner join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {plans_stack}\n",
    "        )\n",
    "    ) as D\n",
    "on\n",
    "    C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "inner join\n",
    "    {nodes} as E\n",
    "on\n",
    "    D.geoid = E.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49beb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "df = pd.read_csv(file+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed62da",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "pq = file /'.parquet'\n",
    "pq.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(pq, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "\"\"\"\n",
    "run_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a63bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "sels = [f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in range (100, 116) if seed != 110]\n",
    "query = \"\\nunion all\\n\".join(sels)\n",
    "query = f\"\"\"\n",
    "    select\n",
    "        A.hash,\n",
    "        max(seed),\n",
    "        max(plan),\n",
    "        count(*) as count\n",
    "    from (\n",
    "        {query}\n",
    "        ) as A\n",
    "    group by\n",
    "        A.hash\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f189bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['seed'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7d6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
