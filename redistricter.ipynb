{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3728aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jupyter/MathVGerrmandering_CMAT_2021\n",
      "Get crosswalks_TX_2010_tabblock   ... tabblock table exists ... success\n",
      "Get assignments_TX_2020_tabblock  ... tabblock table exists ... success\n",
      "Get shapes_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get census_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get elections_TX_2020_tabblock    ... tabblock table exists ... success\n",
      "Get nodes_TX_2020_cntyvtd_sldl_contract10 ... raw table exists ... creating table ... success\n",
      "hashseed != 0 so results are NOT reproducible and will NOT be saved to BigQuery\n",
      "getting edges ... connecting districts\n",
      "District sldl   1 component sizes = [4] ... connected\n",
      "District sldl   2 component sizes = [3] ... connected\n",
      "District sldl   3 component sizes = [26] ... connected\n",
      "District sldl   4 component sizes = [2] ... connected\n",
      "District sldl   5 component sizes = [21] ... connected\n",
      "District sldl   6 component sizes = [57] ... connected\n",
      "District sldl   7 component sizes = [2] ... connected\n",
      "District sldl   8 component sizes = [4] ... connected\n",
      "District sldl   9 component sizes = [6] ... connected\n",
      "District sldl  10 component sizes = [1] ... connected\n",
      "District sldl  11 component sizes = [3] ... connected\n",
      "District sldl  12 component sizes = [80] ... connected\n",
      "District sldl  13 component sizes = [7] ... connected\n",
      "District sldl  14 component sizes = [49] ... connected\n",
      "District sldl  15 component sizes = [37] ... connected\n",
      "District sldl  16 component sizes = [38] ... connected\n",
      "District sldl  17 component sizes = [5] ... connected\n",
      "District sldl  18 component sizes = [3] ... connected\n",
      "District sldl  19 component sizes = [5] ... connected\n",
      "District sldl  20 component sizes = [29] ... connected\n",
      "District sldl  21 component sizes = [42] ... connected\n",
      "District sldl  22 component sizes = [68] ... connected\n",
      "District sldl  23 component sizes = [46] ... connected\n",
      "District sldl  24 component sizes = [47] ... connected\n",
      "District sldl  25 component sizes = [31] ... connected\n",
      "District sldl  26 component sizes = [42] ... connected\n",
      "District sldl  27 component sizes = [54] ... connected\n",
      "District sldl  28 component sizes = [36] ... connected\n",
      "District sldl  29 component sizes = [37] ... connected\n",
      "District sldl  30 component sizes = [6] ... connected\n",
      "District sldl  31 component sizes = [10] ... connected\n",
      "District sldl  32 component sizes = [51] ... connected\n",
      "District sldl  33 component sizes = [36] ... connected\n",
      "District sldl  34 component sizes = [76] ... connected\n",
      "District sldl  35 component sizes = [66] ... connected\n",
      "District sldl  36 component sizes = [45] ... connected\n",
      "District sldl  37 component sizes = [45] ... connected\n",
      "District sldl  38 component sizes = [41] ... connected\n",
      "District sldl  39 component sizes = [63] ... connected\n",
      "District sldl  40 component sizes = [37] ... connected\n",
      "District sldl  41 component sizes = [61] ... connected\n",
      "District sldl  42 component sizes = [49] ... connected\n",
      "District sldl  43 component sizes = [4] ... connected\n",
      "District sldl  44 component sizes = [2] ... connected\n",
      "District sldl  45 component sizes = [69] ... connected\n",
      "District sldl  46 component sizes = [36] ... connected\n",
      "District sldl  47 component sizes = [41] ... connected\n",
      "District sldl  48 component sizes = [50] ... connected\n",
      "District sldl  49 component sizes = [45] ... connected\n",
      "District sldl  50 component sizes = [39] ... connected\n",
      "District sldl  51 component sizes = [36] ... connected\n",
      "District sldl  52 component sizes = [34] ... connected\n",
      "District sldl  53 component sizes = [12] ... connected\n",
      "District sldl  54 component sizes = [21] ... connected\n",
      "District sldl  55 component sizes = [28] ... connected\n",
      "District sldl  56 component sizes = [57] ... connected\n",
      "District sldl  57 component sizes = [6] ... connected\n",
      "District sldl  58 component sizes = [2] ... connected\n",
      "District sldl  59 component sizes = [8] ... connected\n",
      "District sldl  60 component sizes = [8] ... connected\n",
      "District sldl  61 component sizes = [2] ... connected\n",
      "District sldl  62 component sizes = [3] ... connected\n",
      "District sldl  63 component sizes = [45] ... connected\n",
      "District sldl  64 component sizes = [47] ... connected\n",
      "District sldl  65 component sizes = [36] ... connected\n",
      "District sldl  66 component sizes = [42] ... connected\n",
      "District sldl  67 component sizes = [45] ... connected\n",
      "District sldl  68 component sizes = [22] ... connected\n",
      "District sldl  69 component sizes = [6] ... connected\n",
      "District sldl  70 component sizes = [64] ... connected\n",
      "District sldl  71 component sizes = [3] ... connected\n",
      "District sldl  72 component sizes = [9] ... connected\n",
      "District sldl  73 component sizes = [3] ... connected\n",
      "District sldl  74 component sizes = [12] ... connected\n",
      "District sldl  75 component sizes = [37] ... connected\n",
      "District sldl  76 component sizes = [46] ... connected\n",
      "District sldl  77 component sizes = [43] ... connected\n",
      "District sldl  78 component sizes = [43] ... connected\n",
      "District sldl  79 component sizes = [39] ... connected\n",
      "District sldl  80 component sizes = [25] ... connected\n",
      "District sldl  81 component sizes = [4] ... connected\n",
      "District sldl  82 component sizes = [5] ... connected\n",
      "District sldl  83 component sizes = [52] ... connected\n",
      "District sldl  84 component sizes = [51] ... connected\n",
      "District sldl  85 component sizes = [30] ... connected\n",
      "District sldl  86 component sizes = [6] ... connected\n",
      "District sldl  87 component sizes = [5] ... connected\n",
      "District sldl  88 component sizes = [17] ... connected\n",
      "District sldl  89 component sizes = [53] ... connected\n",
      "District sldl  90 component sizes = [90] ... connected\n",
      "District sldl  91 component sizes = [55] ... connected\n",
      "District sldl  92 component sizes = [58] ... connected\n",
      "District sldl  93 component sizes = [74] ... connected\n",
      "District sldl  94 component sizes = [59] ... connected\n",
      "District sldl  95 component sizes = [89] ... connected\n",
      "District sldl  96 component sizes = [55] ... connected\n",
      "District sldl  97 component sizes = [65] ... connected\n",
      "District sldl  98 component sizes = [59] ... connected\n",
      "District sldl  99 component sizes = [73] ... connected\n",
      "District sldl 100 component sizes = [73] ... connected\n",
      "District sldl 101 component sizes = [52] ... connected\n",
      "District sldl 102 component sizes = [46] ... connected\n",
      "District sldl 103 component sizes = [69] ... connected\n",
      "District sldl 104 component sizes = [59] ... connected\n",
      "District sldl 105 component sizes = [58] ... connected\n",
      "District sldl 106 component sizes = [57] ... connected\n",
      "District sldl 107 component sizes = [53] ... connected\n",
      "District sldl 108 component sizes = [66] ... connected\n",
      "District sldl 109 component sizes = [63] ... connected\n",
      "District sldl 110 component sizes = [53] ... connected\n",
      "District sldl 111 component sizes = [57] ... connected\n",
      "District sldl 112 component sizes = [36] ... connected\n",
      "District sldl 113 component sizes = [40] ... connected\n",
      "District sldl 114 component sizes = [69] ... connected\n",
      "District sldl 115 component sizes = [54] ... connected\n",
      "District sldl 116 component sizes = [60] ... connected\n",
      "District sldl 117 component sizes = [74] ... connected\n",
      "District sldl 118 component sizes = [68] ... connected\n",
      "District sldl 119 component sizes = [80] ... connected\n",
      "District sldl 120 component sizes = [87] ... connected\n",
      "District sldl 121 component sizes = [79] ... connected\n",
      "District sldl 122 component sizes = [82] ... connected\n",
      "District sldl 123 component sizes = [94] ... connected\n",
      "District sldl 124 component sizes = [51] ... connected\n",
      "District sldl 125 component sizes = [59] ... connected\n",
      "District sldl 126 component sizes = [35] ... connected\n",
      "District sldl 127 component sizes = [35] ... connected\n",
      "District sldl 128 component sizes = [35] ... connected\n",
      "District sldl 129 component sizes = [49] ... connected\n",
      "District sldl 130 component sizes = [38] ... connected\n",
      "District sldl 131 component sizes = [38] ... connected\n",
      "District sldl 132 component sizes = [32] ... connected\n",
      "District sldl 133 component sizes = [36] ... connected\n",
      "District sldl 134 component sizes = [62] ... connected\n",
      "District sldl 135 component sizes = [30] ... connected\n",
      "District sldl 136 component sizes = [33] ... connected\n",
      "District sldl 137 component sizes = [24] ... connected\n",
      "District sldl 138 component sizes = [35] ... connected\n",
      "District sldl 139 component sizes = [49] ... connected\n",
      "District sldl 140 component sizes = [44] ... connected\n",
      "District sldl 141 component sizes = [53] ... connected\n",
      "District sldl 142 component sizes = [66] ... connected\n",
      "District sldl 143 component sizes = [41] ... connected\n",
      "District sldl 144 component sizes = [40] ... connected\n",
      "District sldl 145 component sizes = [45] ... connected\n",
      "District sldl 146 component sizes = [51] ... connected\n",
      "District sldl 147 component sizes = [61] ... connected\n",
      "District sldl 148 component sizes = [51] ... connected\n",
      "District sldl 149 component sizes = [23] ... connected\n",
      "District sldl 150 component sizes = [38] ... connected\n",
      "\n",
      "random_seed 3005000: step 0 0hrs 0min 8.76sec, pop_imbal=77.6, intersections_defect=330, whole_districts_defect=119\n",
      "total time elapsed = 0hrs 0min 8.76sec\n",
      "total time elapsed = 0hrs 0min 8.76sec\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "run_mcmc = False\n",
    "%run -i redistricter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ec1d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmat-315920.TX_2020_cntyvtd_sldl_contract10.TX_2020_cntyvtd_sldl_contract10_3005000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.results_bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3212bb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from src import *\n",
    "q = f\"select polygon, geoid, sldl, county, total_pop, density, aland, polsby_popper from {proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_sldl_contract10\"\n",
    "df = run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93722a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo0  = gpd.GeoSeries.from_wkt(df['polygon'], crs=crs_census)\n",
    "# geo = gpd.GeoSeries.from_wkt(df['polygon'], crs=crs_census)#.to_crs(crs_area)\n",
    "# geo2 = geo1.buffer(0)\n",
    "# gdf0 = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo0)\n",
    "# gdf1 = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo1)\n",
    "# gdf2 = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo2)\n",
    "\n",
    "# q = pd.DataFrame()\n",
    "# q['orig'] = geo1.area\n",
    "# q['buffer'] = geo2.area\n",
    "# q['pct'] = (q['buffer'] - q['orig']) / q['buffer'] * 100\n",
    "# print(q['pct'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd4c5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = gpd.GeoSeries.from_wkt(df['polygon'], crs=crs_census)#.to_crs(crs_area)\n",
    "gdf = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99784f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf['color'] = gdf['sldl'].sample(1)\n",
    "W = pd.DataFrame()\n",
    "W['sldl'] = gdf['sldl'].unique()\n",
    "W['color'] = np.random.permutation(W['sldl'])\n",
    "gdf = gdf.merge(W, on='sldl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad04e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    import pandas_bokeh\n",
    "except:\n",
    "    os.system('pip install --upgrade pandas-bokeh')\n",
    "    import pandas_bokeh\n",
    "pandas_bokeh.output_notebook() #<------------- uncommment to view in notebook\n",
    "\n",
    "fig = gdf.plot_bokeh(\n",
    "            figsize = (900, 600),\n",
    "#             slider = plans,\n",
    "#             slider_name = \"PLAN #\",\n",
    "            category = 'color',\n",
    "            show_colorbar = False,\n",
    "            colorbar_tick_format=\"0\",\n",
    "            colormap = \"Category20\",\n",
    "            hovertool_string = '@geoid, @sldl<br>@county<br>pop=@total_pop<br>density=@density{0.0}<br>land=@aland{0.0}<br>pp=@polsby_popper{0.0}',\n",
    "            tile_provider = \"CARTODBPOSITRON\",\n",
    "            return_html = False,\n",
    "            show_figure = True,\n",
    "            **{'fill_alpha' :.5,\n",
    "              'line_alpha':.05,}\n",
    "        )\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df):\n",
    "    try:\n",
    "        import pandas_bokeh\n",
    "    except:\n",
    "        os.system('pip install --upgrade pandas-bokeh')\n",
    "        import pandas_bokeh\n",
    "\n",
    "    geo = gpd.GeoSeries.from_wkt(df['polygon'], crs='EPSG:4326').simplify(0.001).buffer(0) #<-- little white space @ .001 ~5.7 mb, minimal at .0001 ~10mb, with no white space ~37mb\n",
    "    gdf = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df):\n",
    "    try:\n",
    "        import pandas_bokeh\n",
    "    except:\n",
    "        os.system('pip install --upgrade pandas-bokeh')\n",
    "        import pandas_bokeh\n",
    "\n",
    "    try:\n",
    "#         df = read_table(tbl=self.tbl+'_plans')\n",
    "        df = df.pivot(index='geoid', columns='plan').astype(int)\n",
    "        df.columns = df.columns.droplevel().rename(None)\n",
    "        d = len(str(df.columns.max()))\n",
    "        plans = ['plan_'+str(c).rjust(d, '0') for c in df.columns]\n",
    "        df.columns = plans\n",
    "\n",
    "        shapes = run_query(f'select geoid, county, total_pop, density, aland, perim, polsby_popper, polygon from {self.nodes}')\n",
    "        df = df.merge(shapes, on='geoid')\n",
    "        geo = gpd.GeoSeries.from_wkt(df['polygon'], crs='EPSG:4326').simplify(0.001).buffer(0) #<-- little white space @ .001 ~5.7 mb, minimal at .0001 ~10mb, with no white space ~37mb\n",
    "#             geo = gpd.GeoSeries.from_wkt(df['polygon'], crs='EPSG:4326').buffer(0) # <-------------------- to not simplify at all\n",
    "        self.gdf = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo)\n",
    "\n",
    "        if show:\n",
    "            pandas_bokeh.output_notebook() #<------------- uncommment to view in notebook\n",
    "        fig = self.gdf.plot_bokeh(\n",
    "            figsize = (900, 600),\n",
    "            slider = plans,\n",
    "            slider_name = \"PLAN #\",\n",
    "            show_colorbar = False,\n",
    "            colorbar_tick_format=\"0\",\n",
    "            colormap = \"Category20\",\n",
    "            hovertool_string = '@geoid, @county<br>pop=@total_pop<br>density=@density{0.0}<br>land=@aland{0.0}<br>pp=@polsby_popper{0.0}',\n",
    "            tile_provider = \"CARTODBPOSITRON\",\n",
    "            return_html = True,\n",
    "            show_figure = show,\n",
    "            **{'fill_alpha' :.5,\n",
    "              'line_alpha':.05,}\n",
    "        )\n",
    "        fn = self.results_path / f'{self.run}_map.html'\n",
    "        with open(fn, 'w') as file:\n",
    "            file.write(fig)\n",
    "#             rpt(f'map creation for {self.seed} - success')\n",
    "    except Exception as e:\n",
    "        rpt(f'map creation for {self.seed} - FAIL {e}')\n",
    "        fig = None\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "for contract_thresh in [0, 5, 10]:\n",
    "    for level in Levels:\n",
    "        for district_type in District_types:\n",
    "            nodes_opts = {\n",
    "                'abbr'             : 'TX',\n",
    "                'level'            : level,\n",
    "                'district_type'    : district_type,\n",
    "                'contract_thresh'  : contract_thresh,\n",
    "            }\n",
    "            %run -i redistricter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc627fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N.tbl.split('.')[-1].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "\n",
    "tbl = f'{root_bq}.TX_2020_cntyvtd_cd.TX_2020_cntyvtd_cd_0000000_allresults'\n",
    "results_stem = tbl.split('.')[1]\n",
    "\n",
    "d = dict()\n",
    "for c in [x for x in [x.split('_') for x in get_cols(tbl)] if x[0] in ['President', 'USSen'] and x[3] in ['R', 'D']]:\n",
    "    a = '_'.join(c[:2])\n",
    "    b = c[3]\n",
    "    c = '_'.join(c)\n",
    "    try:\n",
    "        d[a][b] = c\n",
    "    except:\n",
    "        d[a] = {b:c}\n",
    "\n",
    "for key, val in d.items():\n",
    "    query = f\"\"\"\n",
    "select\n",
    "    seed,\n",
    "    plan,\n",
    "    cd,\n",
    "    V as {key}_DR_votes,\n",
    "    D / V as {key}_D_prop\n",
    "from (\n",
    "    select\n",
    "        *,\n",
    "        D + R as V\n",
    "    from (\n",
    "        select\n",
    "            seed,\n",
    "            plan,\n",
    "            cd,\n",
    "            {val['D']} as D,\n",
    "            {val['R']} as R\n",
    "        from\n",
    "            {tbl}\n",
    "        )\n",
    "    )\n",
    "order by\n",
    "    seed, plan, cd\n",
    "\"\"\"\n",
    "    tbl_out = tbl.replace('allresults', key)\n",
    "    s = tbl_out.split('.')\n",
    "    pq = f'output/{s[1]}/{s[2]}.parquet'\n",
    "    file = root_path / pq\n",
    "    file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    load_table(tbl=tbl_out, query=query)\n",
    "    df = read_table(tbl_out)\n",
    "#     display(df.head(3))\n",
    "#     df.sort_values(['seed', 'plan', 'cd'], inplace=True)\n",
    "#     display(df.head(3))\n",
    "\n",
    "    df.to_parquet(file)\n",
    "    gcs_bucket.blob(str(pq)).upload_from_filename(file)\n",
    "#     del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dbcd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ae1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['seed', 'plan']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4]\n",
    "l[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=G\n",
    "D =2\n",
    "# H = nx.subgraph_view(G.graph, filter_node=lambda n: n.data[self.district_type] == D)\n",
    "H = nx.subgraph_view(self.graph, filter_node=lambda n: self.graph.nodes[n][self.district_type] == D)\n",
    "H.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G, filter_node=lambda n: n.data[self.district_type] == D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71898f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G, filter_node=lambda n: n.data[self.district_type] == D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914db783",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G.graph, filter_node=lambda n: n.data[self.district_type] == D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3cb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = G.graph.nodes(data='cd')\n",
    "g['001']\n",
    "# list(g.nodes)[:10]\n",
    "# x = '161'\n",
    "# rng = np.random.default_rng(11)\n",
    "# # y = rng.choice(g[x])\n",
    "# g.nodes[rng.choice(g[x])]['cd']\n",
    "# # w = g[x]\n",
    "\n",
    "\n",
    "# # w.items()\n",
    "# # d = dict(w)\n",
    "# y = rng.choice(w)\n",
    "# y\n",
    "# g.nodes[y]\n",
    "# w[y]\n",
    "# w\n",
    "# list(g.neighbors(x, data=True))\n",
    "# g.neighbors?\n",
    "# n = rng.choice(dict(g[x]))\n",
    "# g[n]\n",
    "# n\n",
    "\n",
    "# rng.randomg[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "\n",
    "for level in Levels:\n",
    "    for district_type in District_types:\n",
    "        D = list()\n",
    "        for countyline_rule in [0, 2010, 5, 10]:\n",
    "            print(level, district_type, countyline_rule)\n",
    "            graph_opts = {\n",
    "                'abbr'             : 'TX',\n",
    "                'level'            : level,\n",
    "                'district_type'    : district_type,\n",
    "                'census_yr'        : 2020,\n",
    "                'countyline_rule'  : countyline_rule,\n",
    "            }\n",
    "            %run -i redistricter\n",
    "            D.append(f'select * from {G.nodes.tbl}')\n",
    "        t = G.nodes.tbl\n",
    "        combined_tbl = t[:t.rfind('_')] + '_combined'\n",
    "        D = '\\nunion all\\n'.join(D)\n",
    "        query = f\"\"\"\n",
    "select\n",
    "    *\n",
    "from (\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (partition by geoid) as r\n",
    "    from (\n",
    "        {subquery(D, indents=2)}\n",
    "        )\n",
    "    )\n",
    "where\n",
    "    r = 1\n",
    "\"\"\"\n",
    "#         print(combined_tbl)\n",
    "#         print(query)\n",
    "#         assert 1==2\n",
    "        load_table(tbl=combined_tbl, query=query)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = D[0]\n",
    "t[:t.rfind('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "            query = f\"\"\"\n",
    "select\n",
    "    *\n",
    "from (\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (partition by geoid) as r\n",
    "    from (\n",
    "        select * from {A}\n",
    "        union all\n",
    "        select * from {B}\n",
    "        union all\n",
    "        select * from {C}\n",
    "        )\n",
    "    )\n",
    "where\n",
    "    r = 1\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = read_table(G.nodes.tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = n.iloc[:,:4]\n",
    "df = df.groupby('county').agg({'total_pop':'sum', 'cd':'nunique'})\n",
    "ideal_pop = df['total_pop'].sum() / 38\n",
    "df['district_target'] = df['total_pop'] / ideal_pop\n",
    "df.sort_values('district_target')\n",
    "mask = (df['cd'] == 1) ^ (df['district_target'] <= 1)\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea88d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.hash_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "select\n",
    "    *\n",
    "from\n",
    "    {A.tbl} as A\n",
    "inner join (\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        {A.hash_tbl}\n",
    "    where\n",
    "        rand() < 0.01\n",
    "    ) as B\n",
    "on\n",
    "    A.hash_plan = B.hash_plan\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "df.to_parquet(A.pq)\n",
    "to_gcs(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfa8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f28d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_gcs(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hash_plan'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.memory_usage().sum() / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5da92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b16877",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(M.graph.nodes(data='plan'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=M\n",
    "df = self.splits\n",
    "(df['whole_districts_target'] - df['whole_districts']).abs().sum()\n",
    "(df['county_parts_target'] - df['county_parts']).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205c848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=G\n",
    "# w = dict(self.graph.nodes(data='total_pop'))\n",
    "# sorted(w.items(), key=lambda x:x[1], reverse=True)\n",
    "# w = dict(self.graph.nodes(data='total_pop'))\n",
    "sorted(self.graph.nodes(data='total_pop'), key=lambda x:x[1], reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815115d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d['total_pop'] for n, d in G.graph.nodes(data=True)) / 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_districts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = G\n",
    "df = read_table(G.nodes.tbl)\n",
    "idx = df.nlargest(2, 'total_pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.copy()\n",
    "m = n[self.district_type].max()\n",
    "n.loc[idx.index[0], self.district_type] = m+1\n",
    "n.loc[idx.index[1], self.district_type] = m+2\n",
    "m = n[self.district_type].max()\n",
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "(d.max() - d.min()) / pop_ideal * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9456fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d563827",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.copy()\n",
    "m = n[self.district_type].max()\n",
    "n.loc[idx.index[0], self.district_type] = m+1\n",
    "n.loc[idx.index[1], self.district_type] = m+2\n",
    "m = n[self.district_type].max()\n",
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "(d.max() - d.min()) / pop_ideal * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc81e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "d\n",
    "# (d.max() - d.min()) / pop_ideal\n",
    "(d.max() - d.min()) / pop_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.graph.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b23139",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.DataFrame.from_dict(dict(self.graph.nodes(data=True)), orient='index')\n",
    "\n",
    "ideal_pop = round(n['total_pop'].sum() / 38)\n",
    "n['target'] = n.groupby('county')['total_pop'].transform('sum') / ideal_pop\n",
    "n['whole_districts_target'] = np.floor(n['target']).astype(int)\n",
    "n['parts_target'] = np.ceil(n['target']).astype(int)\n",
    "\n",
    "\n",
    "w = n[['county', self.district_type, 'parts_target', 'whole_districts_target']].drop_duplicates()\n",
    "w['whole_district'] = w.groupby(self.district_type)['county'].transform('count') <= 1\n",
    "w['whole_districts'] = w.groupby('county')['whole_district'].transform('sum')\n",
    "w['county_parts'] = w.groupby('county')[self.district_type].transform('count')\n",
    "w.drop(columns=[self.district_type, 'whole_district']).drop_duplicates()\n",
    "# w['parts_error'] = (w['parts_target'] - w['parts']).abs()\n",
    "# w['districts_contained_error'] = (w['districts_contained_target'] - w['districts_contained']).abs()\n",
    "# w.sort_values('parts_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict(self.graph.nodes(data=True)), orient='index').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ea5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.graph.nodes(data=True))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdf916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf7270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f'{root_path}/results/TX_2020_cntyvtd_cd/TX_2020_cntyvtd_cd_0000000_allresults'\n",
    "pq  = file + '.parquet'\n",
    "csv = file + '.csv'\n",
    "df = pd.read_parquet(pq)\n",
    "df.to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "w = 'TX_2020_cntyvtd_cd'\n",
    "bq = f'{proj_id}.w'\n",
    "\n",
    "for tbl in bqclient.list_tables(w):\n",
    "    a = tbl.full_table_id.replace(':','.')\n",
    "    if a.find('allresults') >= 0:\n",
    "        print(f'deleting {a}')\n",
    "        delete_table(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda02ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cols(f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd')[301:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "ds = f'{proj_id}.TX_2020_cntyvtd_cd'\n",
    "for src_tbl in bqclient.list_tables(ds, max_):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.list_tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c33245",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3517f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "for src_tbl in bqclient.list_tables(f'{proj_id}.results'):\n",
    "    w = src_tbl.table_id.split('_')\n",
    "    ds = f'{proj_id}.{\"_\".join(w[:4])}'\n",
    "    dest = f'{ds}.{\"_\".join(w[4:])}'\n",
    "    try:\n",
    "        bqclient.get_table(dest)\n",
    "    except:\n",
    "        print(f'copying {src_tbl.full_table_id} to {dest}')\n",
    "        bqclient.create_dataset(ds, exists_ok=True)\n",
    "        bqclient.copy_table(src_tbl, dest).result()\n",
    "    \n",
    "#     print(src_tbl.table_id, dest_tbl)\n",
    "#     bqclient.copy_table(src_tbl, dest_tbl).result()\n",
    "#     client.delete_table(table_id, not_found_ok=True)\n",
    "#     print(ds)\n",
    "# bqclient.list_tables?\n",
    "# (root)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bqclient.get_table('cmat-315920.TX_2020_cntyvtd_cd.10001_plans')\n",
    "except:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'cmat-315920.results.TX_2020_cntyvtd_cd_0000_plans'\n",
    "check_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75513d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75625d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f499aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "google.cloud.bigquery.job.ExtractJobConfig(destinationFormat='parquet', compression='SNAPPY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c2298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['a'] = ['wab', 'wa1', 'wb2', 'w12']\n",
    "df['b'] = df['a'].str[:-1]\n",
    "df['c'] = df['a'].str[-1]\n",
    "mask = ~df['b'].str[-1].str.isnumeric() & df['c'].str.isnumeric()\n",
    "df.loc[mask, 'c'] = df.loc[mask, 'c'].str.rjust(2, '0')\n",
    "df['d'] = df['b'] + df['c']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f64d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63957b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba75c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pathlib.Path('/home/jupyter/redistricting_data/crosswalks/TX')\n",
    "# f.mkdir()\n",
    "str(f)\n",
    "\n",
    "gcsclient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144af9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(G.crosswalks.pq).replace(str(root_loc), 'gs://bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5ca31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.crosswalks.zip\n",
    "\n",
    "\n",
    "# pq.with_suffix('.temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data_gcs)\n",
    "data_gcs.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_table(G.crosswalks.tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(root_loc / 'temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78a0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet(root_loc / 'temp.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fb888",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_gcs + G.crosswalks.pq.name\n",
    "df2.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2dbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gcs = f'gs://redistricting_data/'\n",
    "f = data_gcs + G.crosswalks.pq.name\n",
    "f\n",
    "bqclient.extract_table(G.crosswalks.tbl, data_gcs + G.crosswalks.pq.name).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.extract_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = root_loc / 'crosswalks_TX_2010.parquet'\n",
    "f\n",
    "df = pd.read_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a891d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f60fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'gs://'+b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "df = pd.DataFrame()\n",
    "# df.to_parquet(b.blob('test'))\n",
    "\n",
    "t = b.blob('test/test2')\n",
    "# df.to_parquet(t)\n",
    "# t.path\n",
    "# g://t.name\n",
    "dir(t)\n",
    "# t._get_download_url(gcsclient)\n",
    "\n",
    "# t.__name__\n",
    "# t.path_helper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dd860",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "c = b.blob('test')\n",
    "c.upload_from_filenameid(root_loc / 'git.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a70289",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_id = 'cmat-315920'\n",
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "# root_gcs.get_blob\n",
    "\n",
    "b = root_gcs.blob('redistricting_data/hi2.txt')#.upload_from_string('hello world')\n",
    "\n",
    "\n",
    "b.blob('sub')\n",
    "# gcsclient.create_bucket?\n",
    "\n",
    "\n",
    "# get_bucket(f'{proj_id}-bucket')\n",
    "# data_gcs = root_gcs.get_blob('redistricting_data/hi.txt')\n",
    "# data_gcs.upload_from_string('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud, pandas as pd\n",
    "cred, proj = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "\n",
    "proj_id = 'cmat-315920'\n",
    "user_name = 'cook'\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bqclient   = google.cloud.bigquery.Client(credentials=cred, project=proj)\n",
    "bqdata     = bqclient.get_dataset(f'redistricting_data')\n",
    "bqresults  = bqclient.get_dataset(f'redistricting_results_{user_name}')\n",
    "\n",
    "L = [x for x in bqclient.list_tables(bqdata)]\n",
    "dir(L[0])\n",
    "t = L[0]\n",
    "t.table_id\n",
    "bqdata.\n",
    "\n",
    "\n",
    "# gcsclient  = google.cloud.storage.Client(credentials=cred, project=proj)\n",
    "# gcsresults = gcsclient.get_bucket(f'redistricting_results')\n",
    "\n",
    "# gcsclient.create_bucket('redistricting_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bqproj = \n",
    "list(bqclient.list_datasets())\n",
    "bqclient.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient   = bigquery.Client(credentials=cred, project=proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e666e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsclient = google.cloud.storage.Client(project=proj_id)\n",
    "list(gcsclient.list_buckets())\n",
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "folder = gcsbucket.blob('test')\n",
    "gcsbucket.exists()\n",
    "folder.exists()\n",
    "gcsbucket.blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "list(gcsbucket.list_blobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63454b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "data_gcs = root_gcs.get_blob('redistricting_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(Base):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bq_results\n",
    "gcs_results\n",
    "\n",
    "\n",
    "results_stem = f'{G.gpickle.stem[6:]}/{timestamp}'\n",
    "\n",
    "results_loc = root_path / f'results/{results_stem}'\n",
    "results_gcs = f'gc://{proj_id}-bucket/results/{results_stem}'\n",
    "results_bq  = f'{proj_id}.{results_stem}'\n",
    "\n",
    "results_loc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gcsclient = storage.Client(project=proj_id)\n",
    "\n",
    "gcsbucket = gcsclient.get_bucket('buckets')\n",
    "blob = bucket.blob('some/folder/name/')\n",
    "bqclient.create_dataset(results_bq, exists_ok=True)\n",
    "results_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6196df",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87006d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133535b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "nodes_tbl = f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "mcmc_tbl  = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_seed_0000'\n",
    "seeds = np.arange(16)\n",
    "A = Analysis(nodes=nodes_tbl, mcmc=mcmc_tbl, seeds=seeds)\n",
    "A.tbl = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "A.fetch_results()\n",
    "A.save_results()\n",
    "# A.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65cd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(A)\n",
    "'_'.join(G.gpickle.stem.split('_')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.tbl.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3100b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.to_parquet(f\"gs://{proj_id}-bucket/{A.tbl.split('.')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=A\n",
    "A.tbl\n",
    "root_path / f'results/{self.tbl.split(\".\")[-1]}.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "idx = ['seed', 'plan', 'cd']\n",
    "for col in idx:\n",
    "    df[col] = rjust(df[col])\n",
    "df.sort_values(idx, inplace=True)\n",
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "file.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(file, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    B.pop_imbalance,\n",
    "    B.polsby_popper as polsby_popper_plan,\n",
    "    C.polsby_popper as polsby_popper_district,\n",
    "    C.total_pop\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0980274",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "nodes = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    E.seed,\n",
    "    E.plan,\n",
    "    E.{district_type},\n",
    "    max(E.pop_imbalance) as pop_imbalance,\n",
    "    max(E.polsby_popper_plan) as polsby_popper_plan,\n",
    "    max(E.polsby_popper_district) as polsby_popper_district,\n",
    "    max(E.total_pop) as total_pop,\n",
    "    sum(F.total_1race)\n",
    "from (\n",
    "    select\n",
    "        B.seed,\n",
    "        B.plan,\n",
    "        C.{district_type},\n",
    "        B.pop_imbalance,\n",
    "        B.polsby_popper as polsby_popper_plan,\n",
    "        C.polsby_popper as polsby_popper_district,\n",
    "        C.total_pop,\n",
    "        D.geoid\n",
    "    from (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            select\n",
    "                *,\n",
    "                row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "            from (\n",
    "                {summary_stack}\n",
    "                ) as A\n",
    "            )\n",
    "        where r = 1\n",
    "        ) as B\n",
    "    inner join (\n",
    "        {stats_stack}\n",
    "        ) as C\n",
    "    on\n",
    "        B.seed = C.seed and B.plan = C.plan\n",
    "    inner join (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            {plans_stack}\n",
    "            )\n",
    "        ) as D\n",
    "    on\n",
    "        C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "    ) as E\n",
    "inner join\n",
    "    {nodes} as F\n",
    "on\n",
    "    E.geoid = F.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "G.nodes_tbl = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "M.tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "cols = [c for c in get_cols(self.nodes) if c not in Levels + District_types + ['geoid', 'county', 'total_pop', 'polygon', 'perim', 'polsby_popper', 'density', 'point']]\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    max(B.pop_imbalance) as pop_imbalance_plan,\n",
    "    max(B.polsby_popper) as polsby_popper_plan,\n",
    "    max(C.polsby_popper) as polsby_popper_district,\n",
    "    max(C.total_pop) as total_pop,\n",
    "    max(C.total_pop) / sum(E.aland) as density,\n",
    "    {join_str(1).join([f'sum(E.{c}) as {c}' for c in cols])}\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "inner join (\n",
    "    {stats_stack}\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "inner join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {plans_stack}\n",
    "        )\n",
    "    ) as D\n",
    "on\n",
    "    C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "inner join\n",
    "    {nodes} as E\n",
    "on\n",
    "    D.geoid = E.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "df = pd.read_csv(file+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "pq = file /'.parquet'\n",
    "pq.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(pq, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "\"\"\"\n",
    "run_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2564f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "sels = [f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in range (100, 116) if seed != 110]\n",
    "query = \"\\nunion all\\n\".join(sels)\n",
    "query = f\"\"\"\n",
    "    select\n",
    "        A.hash,\n",
    "        max(seed),\n",
    "        max(plan),\n",
    "        count(*) as count\n",
    "    from (\n",
    "        {query}\n",
    "        ) as A\n",
    "    group by\n",
    "        A.hash\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9792cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['seed'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e247a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
