{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fdca0726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jupyter/MathVGerrmandering_CMAT_2021\n",
      "Get crosswalks_TX_2010_tabblock   ... tabblock table exists ... success\n",
      "Get assignments_TX_2020_tabblock  ... tabblock table exists ... success\n",
      "Get shapes_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get census_TX_2020_tabblock       ... tabblock table exists ... success\n",
      "Get elections_TX_2020_tabblock    ... tabblock table exists ... success\n",
      "Get nodes_TX_2020_cntyvtd_sldl_contract0 ... cntyvtd table exists ... success\n",
      "stacking hashes into batches\n",
      "0 remain\n",
      "stacking hash batches\n",
      "joining tables in batches\n",
      "0 remain\n",
      "stacking joined table batches\n",
      "joining and aggregating data\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "run_mcmc = True\n",
    "# %run -i redistricter\n",
    "\n",
    "nodes_opts = {\n",
    "    'abbr'             : 'TX',\n",
    "    'level'            : 'cntyvtd',\n",
    "    'district_type'    : 'sldl',\n",
    "    'contract_thresh'  : 0,\n",
    "}\n",
    "N = Nodes(**nodes_opts)\n",
    "M = MCMC(nodes_tbl=N.tbl)\n",
    "M.post_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3436c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_sldl_contract5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MCMC' object has no attribute 'max_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/src/mcmc.py\u001b[0m in \u001b[0;36mpost_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\nunion all\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtbls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msrc_tbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbqclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_bq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0mfull\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msrc_tbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_table_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mshort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_tbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MCMC' object has no attribute 'max_results'"
     ]
    }
   ],
   "source": [
    "M.post_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022f21c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>seats_sldl</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>plan</th>\n",
       "      <th>intersections</th>\n",
       "      <th>whole_districts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113003921</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>0.063159</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>085000136</th>\n",
       "      <td>Collin</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141000096</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>0.022377</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201000170</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0.030385</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>085000034</th>\n",
       "      <td>Collin</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201000341</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0.019212</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201000663</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201000505</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0.048182</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001011</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201000207</th>\n",
       "      <td>Harris</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8698 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            county  seats_sldl  random_seed  plan  intersections  \\\n",
       "geoid                                                              \n",
       "113003921   Dallas    0.063159      1000000     0            778   \n",
       "085000136   Collin    0.014287      1000000     0            236   \n",
       "141000096  El Paso    0.022377      1000000     0            206   \n",
       "201000170   Harris    0.030385      1000000     0            988   \n",
       "085000034   Collin    0.032753      1000000     0            236   \n",
       "...            ...         ...          ...   ...            ...   \n",
       "201000341   Harris    0.019212      1000000     0            988   \n",
       "201000663   Harris    0.019382      1000000     0            988   \n",
       "201000505   Harris    0.048182      1000000     0            988   \n",
       "201001011   Harris    0.000283      1000000     0            988   \n",
       "201000207   Harris    0.008487      1000000     0            988   \n",
       "\n",
       "           whole_districts  \n",
       "geoid                       \n",
       "113003921                0  \n",
       "085000136                0  \n",
       "141000096                0  \n",
       "201000170                0  \n",
       "085000034                0  \n",
       "...                    ...  \n",
       "201000341                0  \n",
       "201000663                0  \n",
       "201000505                0  \n",
       "201001011                0  \n",
       "201000207                0  \n",
       "\n",
       "[8698 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.get_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50851264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole</th>\n",
       "      <th>intersect</th>\n",
       "      <th>target</th>\n",
       "      <th>whole_defect</th>\n",
       "      <th>intersect_defect</th>\n",
       "      <th>defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anderson</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matagorda</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maverick</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McCulloch</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McLennan</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.341094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williamson</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.134362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fort Bend</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.234507</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hays</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240673</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collin</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.478366</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montgomery</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.193166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            whole  intersect    target  whole_defect  intersect_defect  defect\n",
       "county                                                                        \n",
       "Anderson        0          1  0.298101             0                 0       0\n",
       "Matagorda       0          1  0.186590             0                 0       0\n",
       "Maverick        0          1  0.297921             0                 0       0\n",
       "McCulloch       0          1  0.039268             0                 0       0\n",
       "McLennan        1          2  1.341094             0                 0       0\n",
       "...           ...        ...       ...           ...               ...     ...\n",
       "Williamson      2          3  3.134362             1                 1       2\n",
       "Fort Bend       3          4  4.234507             1                 1       2\n",
       "Hays            0          1  1.240673             1                 1       2\n",
       "Collin          4          5  5.478366             1                 1       2\n",
       "Montgomery      2          3  3.193166             1                 1       2\n",
       "\n",
       "[254 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = M\n",
    "df = self.nodes_df[['county', self.district_type, self.seats_col]].drop_duplicates()\n",
    "\n",
    "df = df.groupby(['county', self.district_type])[self.seats_col].sum().reset_index()\n",
    "df['whole'] = df.groupby(self.district_type)['county'].transform('count') <= 1\n",
    "df = df.groupby('county').agg(whole=('whole', 'sum'), intersect=('whole', 'count'), target=('seats_sldl', 'sum'))\n",
    "df['whole_defect'] = (np.floor(df['target']) - df['whole']).abs().astype(int)\n",
    "df['intersect_defect'] = (np.ceil(df['target']) - df['intersect']).abs().astype(int)\n",
    "df['defect'] = df['whole_defect'] + df['intersect_defect']\n",
    "\n",
    "# [['seats_sldl','whole']].sum()\n",
    "\n",
    "\n",
    "# df['whole_districts'] = df.groupby('county')['whole'].transform('sum')\n",
    "df\n",
    "df.sort_values('defect')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e0fb47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/jupyter/MathVGerrmandering_CMAT_2021/redistricter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_bq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    }
   ],
   "source": [
    "M.results_bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32121cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from src import *\n",
    "tbl = f'{proj_id}.reredistricting_data.nodes_TX_2020_cntyvtd_sldl_contract10'\n",
    "\n",
    "tbl = f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_sldl_contract10'\n",
    "\n",
    "q = f\"select polygon, geoid, sldl, county, total_pop, density, aland, polsby_popper from {tbl}\"\n",
    "df = run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo0  = gpd.GeoSeries.from_wkt(df['polygon'], crs=crs_census)\n",
    "# geo = gpd.GeoSeries.from_wkt(df['polygon'], crs=crs_census)#.to_crs(crs_area)\n",
    "# geo2 = geo1.buffer(0)\n",
    "# gdf0 = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo0)\n",
    "# gdf1 = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo1)\n",
    "# gdf2 = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo2)\n",
    "\n",
    "# q = pd.DataFrame()\n",
    "# q['orig'] = geo1.area\n",
    "# q['buffer'] = geo2.area\n",
    "# q['pct'] = (q['buffer'] - q['orig']) / q['buffer'] * 100\n",
    "# print(q['pct'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dab81615",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = gpd.GeoSeries.from_wkt(df['polygon'], crs=crs_census)#.to_crs(crs_area)\n",
    "gdf = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "845604bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf['color'] = gdf['sldl'].sample(1)\n",
    "W = pd.DataFrame()\n",
    "W['sldl'] = gdf['sldl'].unique()\n",
    "W['color'] = np.random.permutation(W['sldl'])\n",
    "gdf = gdf.merge(W, on='sldl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2679a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    import pandas_bokeh\n",
    "except:\n",
    "    os.system('pip install --upgrade pandas-bokeh')\n",
    "    import pandas_bokeh\n",
    "pandas_bokeh.output_notebook() #<------------- uncommment to view in notebook\n",
    "\n",
    "fig = gdf.plot_bokeh(\n",
    "            figsize = (900, 600),\n",
    "#             slider = plans,\n",
    "#             slider_name = \"PLAN #\",\n",
    "            category = 'color',\n",
    "            show_colorbar = False,\n",
    "            colorbar_tick_format=\"0\",\n",
    "            colormap = \"Category20\",\n",
    "            hovertool_string = '@geoid, @sldl<br>@county<br>pop=@total_pop<br>density=@density{0.0}<br>land=@aland{0.0}<br>pp=@polsby_popper{0.0}',\n",
    "            tile_provider = \"CARTODBPOSITRON\",\n",
    "            return_html = False,\n",
    "            show_figure = True,\n",
    "            **{'fill_alpha' :.5,\n",
    "              'line_alpha':.05,}\n",
    "        )\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df):\n",
    "    try:\n",
    "        import pandas_bokeh\n",
    "    except:\n",
    "        os.system('pip install --upgrade pandas-bokeh')\n",
    "        import pandas_bokeh\n",
    "\n",
    "    geo = gpd.GeoSeries.from_wkt(df['polygon'], crs='EPSG:4326').simplify(0.001).buffer(0) #<-- little white space @ .001 ~5.7 mb, minimal at .0001 ~10mb, with no white space ~37mb\n",
    "    gdf = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b69ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df):\n",
    "    try:\n",
    "        import pandas_bokeh\n",
    "    except:\n",
    "        os.system('pip install --upgrade pandas-bokeh')\n",
    "        import pandas_bokeh\n",
    "\n",
    "    try:\n",
    "#         df = read_table(tbl=self.tbl+'_plans')\n",
    "        df = df.pivot(index='geoid', columns='plan').astype(int)\n",
    "        df.columns = df.columns.droplevel().rename(None)\n",
    "        d = len(str(df.columns.max()))\n",
    "        plans = ['plan_'+str(c).rjust(d, '0') for c in df.columns]\n",
    "        df.columns = plans\n",
    "\n",
    "        shapes = run_query(f'select geoid, county, total_pop, density, aland, perim, polsby_popper, polygon from {self.nodes}')\n",
    "        df = df.merge(shapes, on='geoid')\n",
    "        geo = gpd.GeoSeries.from_wkt(df['polygon'], crs='EPSG:4326').simplify(0.001).buffer(0) #<-- little white space @ .001 ~5.7 mb, minimal at .0001 ~10mb, with no white space ~37mb\n",
    "#             geo = gpd.GeoSeries.from_wkt(df['polygon'], crs='EPSG:4326').buffer(0) # <-------------------- to not simplify at all\n",
    "        self.gdf = gpd.GeoDataFrame(df.drop(columns='polygon'), geometry=geo)\n",
    "\n",
    "        if show:\n",
    "            pandas_bokeh.output_notebook() #<------------- uncommment to view in notebook\n",
    "        fig = self.gdf.plot_bokeh(\n",
    "            figsize = (900, 600),\n",
    "            slider = plans,\n",
    "            slider_name = \"PLAN #\",\n",
    "            show_colorbar = False,\n",
    "            colorbar_tick_format=\"0\",\n",
    "            colormap = \"Category20\",\n",
    "            hovertool_string = '@geoid, @county<br>pop=@total_pop<br>density=@density{0.0}<br>land=@aland{0.0}<br>pp=@polsby_popper{0.0}',\n",
    "            tile_provider = \"CARTODBPOSITRON\",\n",
    "            return_html = True,\n",
    "            show_figure = show,\n",
    "            **{'fill_alpha' :.5,\n",
    "              'line_alpha':.05,}\n",
    "        )\n",
    "        fn = self.results_path / f'{self.run}_map.html'\n",
    "        with open(fn, 'w') as file:\n",
    "            file.write(fig)\n",
    "#             rpt(f'map creation for {self.seed} - success')\n",
    "    except Exception as e:\n",
    "        rpt(f'map creation for {self.seed} - FAIL {e}')\n",
    "        fig = None\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f9518",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "for contract_thresh in [0, 5, 10]:\n",
    "    for level in Levels:\n",
    "        for district_type in District_types:\n",
    "            nodes_opts = {\n",
    "                'abbr'             : 'TX',\n",
    "                'level'            : level,\n",
    "                'district_type'    : district_type,\n",
    "                'contract_thresh'  : contract_thresh,\n",
    "            }\n",
    "            %run -i redistricter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "N.tbl.split('.')[-1].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0593f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "\n",
    "tbl = f'{root_bq}.TX_2020_cntyvtd_cd.TX_2020_cntyvtd_cd_0000000_allresults'\n",
    "results_stem = tbl.split('.')[1]\n",
    "\n",
    "d = dict()\n",
    "for c in [x for x in [x.split('_') for x in get_cols(tbl)] if x[0] in ['President', 'USSen'] and x[3] in ['R', 'D']]:\n",
    "    a = '_'.join(c[:2])\n",
    "    b = c[3]\n",
    "    c = '_'.join(c)\n",
    "    try:\n",
    "        d[a][b] = c\n",
    "    except:\n",
    "        d[a] = {b:c}\n",
    "\n",
    "for key, val in d.items():\n",
    "    query = f\"\"\"\n",
    "select\n",
    "    seed,\n",
    "    plan,\n",
    "    cd,\n",
    "    V as {key}_DR_votes,\n",
    "    D / V as {key}_D_prop\n",
    "from (\n",
    "    select\n",
    "        *,\n",
    "        D + R as V\n",
    "    from (\n",
    "        select\n",
    "            seed,\n",
    "            plan,\n",
    "            cd,\n",
    "            {val['D']} as D,\n",
    "            {val['R']} as R\n",
    "        from\n",
    "            {tbl}\n",
    "        )\n",
    "    )\n",
    "order by\n",
    "    seed, plan, cd\n",
    "\"\"\"\n",
    "    tbl_out = tbl.replace('allresults', key)\n",
    "    s = tbl_out.split('.')\n",
    "    pq = f'output/{s[1]}/{s[2]}.parquet'\n",
    "    file = root_path / pq\n",
    "    file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    load_table(tbl=tbl_out, query=query)\n",
    "    df = read_table(tbl_out)\n",
    "#     display(df.head(3))\n",
    "#     df.sort_values(['seed', 'plan', 'cd'], inplace=True)\n",
    "#     display(df.head(3))\n",
    "\n",
    "    df.to_parquet(file)\n",
    "    gcs_bucket.blob(str(pq)).upload_from_filename(file)\n",
    "#     del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a23ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b371105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['seed', 'plan']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7624fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4]\n",
    "l[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc90ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=G\n",
    "D =2\n",
    "# H = nx.subgraph_view(G.graph, filter_node=lambda n: n.data[self.district_type] == D)\n",
    "H = nx.subgraph_view(self.graph, filter_node=lambda n: self.graph.nodes[n][self.district_type] == D)\n",
    "H.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G, filter_node=lambda n: n.data[self.district_type] == D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22118cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G, filter_node=lambda n: n.data[self.district_type] == D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.subgraph_view(G.graph, filter_node=lambda n: n.data[self.district_type] == D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = G.graph.nodes(data='cd')\n",
    "g['001']\n",
    "# list(g.nodes)[:10]\n",
    "# x = '161'\n",
    "# rng = np.random.default_rng(11)\n",
    "# # y = rng.choice(g[x])\n",
    "# g.nodes[rng.choice(g[x])]['cd']\n",
    "# # w = g[x]\n",
    "\n",
    "\n",
    "# # w.items()\n",
    "# # d = dict(w)\n",
    "# y = rng.choice(w)\n",
    "# y\n",
    "# g.nodes[y]\n",
    "# w[y]\n",
    "# w\n",
    "# list(g.neighbors(x, data=True))\n",
    "# g.neighbors?\n",
    "# n = rng.choice(dict(g[x]))\n",
    "# g[n]\n",
    "# n\n",
    "\n",
    "# rng.randomg[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "notebook = True\n",
    "skip_inputs = 'y'\n",
    "\n",
    "for level in Levels:\n",
    "    for district_type in District_types:\n",
    "        D = list()\n",
    "        for countyline_rule in [0, 2010, 5, 10]:\n",
    "            print(level, district_type, countyline_rule)\n",
    "            graph_opts = {\n",
    "                'abbr'             : 'TX',\n",
    "                'level'            : level,\n",
    "                'district_type'    : district_type,\n",
    "                'census_yr'        : 2020,\n",
    "                'countyline_rule'  : countyline_rule,\n",
    "            }\n",
    "            %run -i redistricter\n",
    "            D.append(f'select * from {G.nodes.tbl}')\n",
    "        t = G.nodes.tbl\n",
    "        combined_tbl = t[:t.rfind('_')] + '_combined'\n",
    "        D = '\\nunion all\\n'.join(D)\n",
    "        query = f\"\"\"\n",
    "select\n",
    "    *\n",
    "from (\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (partition by geoid) as r\n",
    "    from (\n",
    "        {subquery(D, indents=2)}\n",
    "        )\n",
    "    )\n",
    "where\n",
    "    r = 1\n",
    "\"\"\"\n",
    "#         print(combined_tbl)\n",
    "#         print(query)\n",
    "#         assert 1==2\n",
    "        load_table(tbl=combined_tbl, query=query)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99970ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = D[0]\n",
    "t[:t.rfind('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "            query = f\"\"\"\n",
    "select\n",
    "    *\n",
    "from (\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (partition by geoid) as r\n",
    "    from (\n",
    "        select * from {A}\n",
    "        union all\n",
    "        select * from {B}\n",
    "        union all\n",
    "        select * from {C}\n",
    "        )\n",
    "    )\n",
    "where\n",
    "    r = 1\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0172b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = read_table(G.nodes.tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = n.iloc[:,:4]\n",
    "df = df.groupby('county').agg({'total_pop':'sum', 'cd':'nunique'})\n",
    "ideal_pop = df['total_pop'].sum() / 38\n",
    "df['district_target'] = df['total_pop'] / ideal_pop\n",
    "df.sort_values('district_target')\n",
    "mask = (df['cd'] == 1) ^ (df['district_target'] <= 1)\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b119cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.hash_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "select\n",
    "    *\n",
    "from\n",
    "    {A.tbl} as A\n",
    "inner join (\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        {A.hash_tbl}\n",
    "    where\n",
    "        rand() < 0.01\n",
    "    ) as B\n",
    "on\n",
    "    A.hash_plan = B.hash_plan\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "df.to_parquet(A.pq)\n",
    "to_gcs(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ffe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_gcs(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ba63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hash_plan'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.memory_usage().sum() / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(A.pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ba443",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(M.graph.nodes(data='plan'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cebaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=M\n",
    "df = self.splits\n",
    "(df['whole_districts_target'] - df['whole_districts']).abs().sum()\n",
    "(df['county_parts_target'] - df['county_parts']).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce545a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=G\n",
    "# w = dict(self.graph.nodes(data='total_pop'))\n",
    "# sorted(w.items(), key=lambda x:x[1], reverse=True)\n",
    "# w = dict(self.graph.nodes(data='total_pop'))\n",
    "sorted(self.graph.nodes(data='total_pop'), key=lambda x:x[1], reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d['total_pop'] for n, d in G.graph.nodes(data=True)) / 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.get_districts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3915e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e396188",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = G\n",
    "df = read_table(G.nodes.tbl)\n",
    "idx = df.nlargest(2, 'total_pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.copy()\n",
    "m = n[self.district_type].max()\n",
    "n.loc[idx.index[0], self.district_type] = m+1\n",
    "n.loc[idx.index[1], self.district_type] = m+2\n",
    "m = n[self.district_type].max()\n",
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "(d.max() - d.min()) / pop_ideal * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e53a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.copy()\n",
    "m = n[self.district_type].max()\n",
    "n.loc[idx.index[0], self.district_type] = m+1\n",
    "n.loc[idx.index[1], self.district_type] = m+2\n",
    "m = n[self.district_type].max()\n",
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "(d.max() - d.min()) / pop_ideal * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4daaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ideal = round(n['total_pop'].sum() / m)\n",
    "d = n.groupby(self.district_type)['total_pop'].sum()\n",
    "d\n",
    "# (d.max() - d.min()) / pop_ideal\n",
    "(d.max() - d.min()) / pop_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.graph.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.DataFrame.from_dict(dict(self.graph.nodes(data=True)), orient='index')\n",
    "\n",
    "ideal_pop = round(n['total_pop'].sum() / 38)\n",
    "n['target'] = n.groupby('county')['total_pop'].transform('sum') / ideal_pop\n",
    "n['whole_districts_target'] = np.floor(n['target']).astype(int)\n",
    "n['parts_target'] = np.ceil(n['target']).astype(int)\n",
    "\n",
    "\n",
    "w = n[['county', self.district_type, 'parts_target', 'whole_districts_target']].drop_duplicates()\n",
    "w['whole_district'] = w.groupby(self.district_type)['county'].transform('count') <= 1\n",
    "w['whole_districts'] = w.groupby('county')['whole_district'].transform('sum')\n",
    "w['county_parts'] = w.groupby('county')[self.district_type].transform('count')\n",
    "w.drop(columns=[self.district_type, 'whole_district']).drop_duplicates()\n",
    "# w['parts_error'] = (w['parts_target'] - w['parts']).abs()\n",
    "# w['districts_contained_error'] = (w['districts_contained_target'] - w['districts_contained']).abs()\n",
    "# w.sort_values('parts_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc03a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict(self.graph.nodes(data=True)), orient='index').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self.graph.nodes(data=True))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f616e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f0147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f'{root_path}/results/TX_2020_cntyvtd_cd/TX_2020_cntyvtd_cd_0000000_allresults'\n",
    "pq  = file + '.parquet'\n",
    "csv = file + '.csv'\n",
    "df = pd.read_parquet(pq)\n",
    "df.to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e15793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "w = 'TX_2020_cntyvtd_cd'\n",
    "bq = f'{proj_id}.w'\n",
    "\n",
    "for tbl in bqclient.list_tables(w):\n",
    "    a = tbl.full_table_id.replace(':','.')\n",
    "    if a.find('allresults') >= 0:\n",
    "        print(f'deleting {a}')\n",
    "        delete_table(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cols(f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd')[301:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ce32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "ds = f'{proj_id}.TX_2020_cntyvtd_cd'\n",
    "for src_tbl in bqclient.list_tables(ds, max_):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.list_tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9eb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "for src_tbl in bqclient.list_tables(f'{proj_id}.results'):\n",
    "    w = src_tbl.table_id.split('_')\n",
    "    ds = f'{proj_id}.{\"_\".join(w[:4])}'\n",
    "    dest = f'{ds}.{\"_\".join(w[4:])}'\n",
    "    try:\n",
    "        bqclient.get_table(dest)\n",
    "    except:\n",
    "        print(f'copying {src_tbl.full_table_id} to {dest}')\n",
    "        bqclient.create_dataset(ds, exists_ok=True)\n",
    "        bqclient.copy_table(src_tbl, dest).result()\n",
    "    \n",
    "#     print(src_tbl.table_id, dest_tbl)\n",
    "#     bqclient.copy_table(src_tbl, dest_tbl).result()\n",
    "#     client.delete_table(table_id, not_found_ok=True)\n",
    "#     print(ds)\n",
    "# bqclient.list_tables?\n",
    "# (root)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bqclient.get_table('cmat-315920.TX_2020_cntyvtd_cd.10001_plans')\n",
    "except:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'cmat-315920.results.TX_2020_cntyvtd_cd_0000_plans'\n",
    "check_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08abcd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "google.cloud.bigquery.job.ExtractJobConfig(destinationFormat='parquet', compression='SNAPPY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['a'] = ['wab', 'wa1', 'wb2', 'w12']\n",
    "df['b'] = df['a'].str[:-1]\n",
    "df['c'] = df['a'].str[-1]\n",
    "mask = ~df['b'].str[-1].str.isnumeric() & df['c'].str.isnumeric()\n",
    "df.loc[mask, 'c'] = df.loc[mask, 'c'].str.rjust(2, '0')\n",
    "df['d'] = df['b'] + df['c']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aaabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pathlib.Path('/home/jupyter/redistricting_data/crosswalks/TX')\n",
    "# f.mkdir()\n",
    "str(f)\n",
    "\n",
    "gcsclient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(G.crosswalks.pq).replace(str(root_loc), 'gs://bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d62ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.crosswalks.zip\n",
    "\n",
    "\n",
    "# pq.with_suffix('.temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data_gcs)\n",
    "data_gcs.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c90438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_table(G.crosswalks.tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d71423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(root_loc / 'temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a007ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d87935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet(root_loc / 'temp.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba59d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782452d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_gcs + G.crosswalks.pq.name\n",
    "df2.to_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeafb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedc230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f229045",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gcs = f'gs://redistricting_data/'\n",
    "f = data_gcs + G.crosswalks.pq.name\n",
    "f\n",
    "bqclient.extract_table(G.crosswalks.tbl, data_gcs + G.crosswalks.pq.name).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cda673",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.extract_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17794243",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = root_loc / 'crosswalks_TX_2010.parquet'\n",
    "f\n",
    "df = pd.read_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ff9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a89aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'gs://'+b.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db380b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "df = pd.DataFrame()\n",
    "# df.to_parquet(b.blob('test'))\n",
    "\n",
    "t = b.blob('test/test2')\n",
    "# df.to_parquet(t)\n",
    "# t.path\n",
    "# g://t.name\n",
    "dir(t)\n",
    "# t._get_download_url(gcsclient)\n",
    "\n",
    "# t.__name__\n",
    "# t.path_helper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74bb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gcsclient.get_bucket(f'math_for_unbiased_maps_tx')\n",
    "c = b.blob('test')\n",
    "c.upload_from_filenameid(root_loc / 'git.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_id = 'cmat-315920'\n",
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "# root_gcs.get_blob\n",
    "\n",
    "b = root_gcs.blob('redistricting_data/hi2.txt')#.upload_from_string('hello world')\n",
    "\n",
    "\n",
    "b.blob('sub')\n",
    "# gcsclient.create_bucket?\n",
    "\n",
    "\n",
    "# get_bucket(f'{proj_id}-bucket')\n",
    "# data_gcs = root_gcs.get_blob('redistricting_data/hi.txt')\n",
    "# data_gcs.upload_from_string('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f987ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud, pandas as pd\n",
    "cred, proj = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "\n",
    "proj_id = 'cmat-315920'\n",
    "user_name = 'cook'\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bqclient   = google.cloud.bigquery.Client(credentials=cred, project=proj)\n",
    "bqdata     = bqclient.get_dataset(f'redistricting_data')\n",
    "bqresults  = bqclient.get_dataset(f'redistricting_results_{user_name}')\n",
    "\n",
    "L = [x for x in bqclient.list_tables(bqdata)]\n",
    "dir(L[0])\n",
    "t = L[0]\n",
    "t.table_id\n",
    "bqdata.\n",
    "\n",
    "\n",
    "# gcsclient  = google.cloud.storage.Client(credentials=cred, project=proj)\n",
    "# gcsresults = gcsclient.get_bucket(f'redistricting_results')\n",
    "\n",
    "# gcsclient.create_bucket('redistricting_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7790f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bqproj = \n",
    "list(bqclient.list_datasets())\n",
    "bqclient.project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7afbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient   = bigquery.Client(credentials=cred, project=proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsclient = google.cloud.storage.Client(project=proj_id)\n",
    "list(gcsclient.list_buckets())\n",
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "folder = gcsbucket.blob('test')\n",
    "gcsbucket.exists()\n",
    "folder.exists()\n",
    "gcsbucket.blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1904754",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsbucket = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "list(gcsbucket.list_blobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_gcs = gcsclient.get_bucket(f'{proj_id}-bucket')\n",
    "data_gcs = root_gcs.get_blob('redistricting_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results(Base):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "timestamp = str(pd.Timestamp.now().round(\"s\")).replace(' ','_').replace('-','_').replace(':','_')\n",
    "\n",
    "bq_results\n",
    "gcs_results\n",
    "\n",
    "\n",
    "results_stem = f'{G.gpickle.stem[6:]}/{timestamp}'\n",
    "\n",
    "results_loc = root_path / f'results/{results_stem}'\n",
    "results_gcs = f'gc://{proj_id}-bucket/results/{results_stem}'\n",
    "results_bq  = f'{proj_id}.{results_stem}'\n",
    "\n",
    "results_loc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gcsclient = storage.Client(project=proj_id)\n",
    "\n",
    "gcsbucket = gcsclient.get_bucket('buckets')\n",
    "blob = bucket.blob('some/folder/name/')\n",
    "bqclient.create_dataset(results_bq, exists_ok=True)\n",
    "results_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e283b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b063108",
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient.create_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239ae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "nodes_tbl = f'{proj_id}.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "mcmc_tbl  = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_seed_0000'\n",
    "seeds = np.arange(16)\n",
    "A = Analysis(nodes=nodes_tbl, mcmc=mcmc_tbl, seeds=seeds)\n",
    "A.tbl = f'{proj_id}.redistricting_results_cook.TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "A.fetch_results()\n",
    "A.save_results()\n",
    "# A.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da953a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(A)\n",
    "'_'.join(G.gpickle.stem.split('_')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef77f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.tbl.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91daf9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.to_parquet(f\"gs://{proj_id}-bucket/{A.tbl.split('.')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "self=A\n",
    "A.tbl\n",
    "root_path / f'results/{self.tbl.split(\".\")[-1]}.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc84813",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from src import *\n",
    "\n",
    "idx = ['seed', 'plan', 'cd']\n",
    "for col in idx:\n",
    "    df[col] = rjust(df[col])\n",
    "df.sort_values(idx, inplace=True)\n",
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "file.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(file, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd131545",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    B.pop_imbalance,\n",
    "    B.polsby_popper as polsby_popper_plan,\n",
    "    C.polsby_popper as polsby_popper_district,\n",
    "    C.total_pop\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdc5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "nodes = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    E.seed,\n",
    "    E.plan,\n",
    "    E.{district_type},\n",
    "    max(E.pop_imbalance) as pop_imbalance,\n",
    "    max(E.polsby_popper_plan) as polsby_popper_plan,\n",
    "    max(E.polsby_popper_district) as polsby_popper_district,\n",
    "    max(E.total_pop) as total_pop,\n",
    "    sum(F.total_1race)\n",
    "from (\n",
    "    select\n",
    "        B.seed,\n",
    "        B.plan,\n",
    "        C.{district_type},\n",
    "        B.pop_imbalance,\n",
    "        B.polsby_popper as polsby_popper_plan,\n",
    "        C.polsby_popper as polsby_popper_district,\n",
    "        C.total_pop,\n",
    "        D.geoid\n",
    "    from (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            select\n",
    "                *,\n",
    "                row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "            from (\n",
    "                {summary_stack}\n",
    "                ) as A\n",
    "            )\n",
    "        where r = 1\n",
    "        ) as B\n",
    "    inner join (\n",
    "        {stats_stack}\n",
    "        ) as C\n",
    "    on\n",
    "        B.seed = C.seed and B.plan = C.plan\n",
    "    inner join (\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            {plans_stack}\n",
    "            )\n",
    "        ) as D\n",
    "    on\n",
    "        C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "    ) as E\n",
    "inner join\n",
    "    {nodes} as F\n",
    "on\n",
    "    E.geoid = F.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73520f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_type = 'cd'\n",
    "\n",
    "G.nodes_tbl = f'cmat-315920.redistricting_data.nodes_TX_2020_cntyvtd_cd'\n",
    "M.tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "\n",
    "s = \"\\nunion all\\n\"\n",
    "seeds = [s for s in range (100, 116) if s not in [104, 110]]\n",
    "summary_stack = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in seeds])\n",
    "stats_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_stats'   for seed in seeds])\n",
    "plans_stack   = s.join([f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_plans'   for seed in seeds])\n",
    "\n",
    "cols = [c for c in get_cols(self.nodes) if c not in Levels + District_types + ['geoid', 'county', 'total_pop', 'polygon', 'perim', 'polsby_popper', 'density', 'point']]\n",
    "\n",
    "query = f\"\"\"\n",
    "select\n",
    "    B.seed,\n",
    "    B.plan,\n",
    "    C.{district_type},\n",
    "    max(B.pop_imbalance) as pop_imbalance_plan,\n",
    "    max(B.polsby_popper) as polsby_popper_plan,\n",
    "    max(C.polsby_popper) as polsby_popper_district,\n",
    "    max(C.total_pop) as total_pop,\n",
    "    max(C.total_pop) / sum(E.aland) as density,\n",
    "    {join_str(1).join([f'sum(E.{c}) as {c}' for c in cols])}\n",
    "from (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        select\n",
    "            *,\n",
    "            row_number() over (partition by A.hash order by plan asc, seed asc) as r\n",
    "        from (\n",
    "            {summary_stack}\n",
    "            ) as A\n",
    "        )\n",
    "    where r = 1\n",
    "    ) as B\n",
    "inner join (\n",
    "    {stats_stack}\n",
    "    ) as C\n",
    "on\n",
    "    B.seed = C.seed and B.plan = C.plan\n",
    "inner join (\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {plans_stack}\n",
    "        )\n",
    "    ) as D\n",
    "on\n",
    "    C.seed = D.seed and C.plan = D.plan and C.{district_type} = D.{district_type}\n",
    "inner join\n",
    "    {nodes} as E\n",
    "on\n",
    "    D.geoid = E.geoid\n",
    "group by\n",
    "    seed, plan, {district_type}\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df#['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6292c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26'\n",
    "df = pd.read_csv(file+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pathlib.Path('/home/jupyter/results/TX_2020_cntyvtd_cd_2021_09_05_01_50_26')\n",
    "pq = file /'.parquet'\n",
    "pq.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(pq, index=False, partition_cols='seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    select\n",
    "        *\n",
    "    from (\n",
    "        {stats_stack}\n",
    "        )\n",
    "\"\"\"\n",
    "run_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a401cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = f'cmat-315920.redistricting_results_cook.TX_2020_cntyvtd_cd_seed'\n",
    "sels = [f'select * from {tbl}_{str(seed).rjust(4, \"0\")}_summary' for seed in range (100, 116) if seed != 110]\n",
    "query = \"\\nunion all\\n\".join(sels)\n",
    "query = f\"\"\"\n",
    "    select\n",
    "        A.hash,\n",
    "        max(seed),\n",
    "        max(plan),\n",
    "        count(*) as count\n",
    "    from (\n",
    "        {query}\n",
    "        ) as A\n",
    "    group by\n",
    "        A.hash\n",
    "\"\"\"\n",
    "df = run_query(query)\n",
    "# \n",
    "df['hash'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29400df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['seed'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe0cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
