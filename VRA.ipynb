{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e9cecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using local /home/jupyter/redistricting_data/vra_cntyvtd.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntyvtd</th>\n",
       "      <th>county</th>\n",
       "      <th>vap_pop</th>\n",
       "      <th>density</th>\n",
       "      <th>vap_hisp_pct</th>\n",
       "      <th>vap_black_pct</th>\n",
       "      <th>vap_white_pct</th>\n",
       "      <th>dist_border</th>\n",
       "      <th>Pres_20_red_pct</th>\n",
       "      <th>Pres_16_red_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>Sen_12_Sadler</th>\n",
       "      <th>Sen_12_Cruz</th>\n",
       "      <th>Pres_20_votes</th>\n",
       "      <th>Pres_16_votes</th>\n",
       "      <th>Pres_12_votes</th>\n",
       "      <th>Sen_20_votes</th>\n",
       "      <th>Sen_18_votes</th>\n",
       "      <th>Sen_14_votes</th>\n",
       "      <th>Sen_12_votes</th>\n",
       "      <th>aland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>025000018</td>\n",
       "      <td>Bee</td>\n",
       "      <td>1852</td>\n",
       "      <td>42.830818</td>\n",
       "      <td>46.004320</td>\n",
       "      <td>3.023758</td>\n",
       "      <td>50.971922</td>\n",
       "      <td>117.849478</td>\n",
       "      <td>73.809524</td>\n",
       "      <td>74.139729</td>\n",
       "      <td>...</td>\n",
       "      <td>268</td>\n",
       "      <td>682</td>\n",
       "      <td>1134</td>\n",
       "      <td>959</td>\n",
       "      <td>994</td>\n",
       "      <td>1100</td>\n",
       "      <td>970</td>\n",
       "      <td>639</td>\n",
       "      <td>950</td>\n",
       "      <td>43.239893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>025000013</td>\n",
       "      <td>Bee</td>\n",
       "      <td>1577</td>\n",
       "      <td>10.903907</td>\n",
       "      <td>62.396956</td>\n",
       "      <td>0.443881</td>\n",
       "      <td>37.159163</td>\n",
       "      <td>111.368878</td>\n",
       "      <td>65.120968</td>\n",
       "      <td>59.210526</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>412</td>\n",
       "      <td>992</td>\n",
       "      <td>760</td>\n",
       "      <td>712</td>\n",
       "      <td>930</td>\n",
       "      <td>655</td>\n",
       "      <td>445</td>\n",
       "      <td>685</td>\n",
       "      <td>144.627052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>025000009</td>\n",
       "      <td>Bee</td>\n",
       "      <td>764</td>\n",
       "      <td>723.040307</td>\n",
       "      <td>88.350785</td>\n",
       "      <td>1.701571</td>\n",
       "      <td>9.947644</td>\n",
       "      <td>119.880787</td>\n",
       "      <td>42.953020</td>\n",
       "      <td>27.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>273</td>\n",
       "      <td>87</td>\n",
       "      <td>447</td>\n",
       "      <td>429</td>\n",
       "      <td>387</td>\n",
       "      <td>411</td>\n",
       "      <td>334</td>\n",
       "      <td>288</td>\n",
       "      <td>360</td>\n",
       "      <td>1.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>025000002</td>\n",
       "      <td>Bee</td>\n",
       "      <td>213</td>\n",
       "      <td>3.639055</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>1.877934</td>\n",
       "      <td>64.788732</td>\n",
       "      <td>112.012345</td>\n",
       "      <td>90.109890</td>\n",
       "      <td>91.351351</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>129</td>\n",
       "      <td>182</td>\n",
       "      <td>185</td>\n",
       "      <td>165</td>\n",
       "      <td>176</td>\n",
       "      <td>167</td>\n",
       "      <td>119</td>\n",
       "      <td>154</td>\n",
       "      <td>58.531673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>025000008</td>\n",
       "      <td>Bee</td>\n",
       "      <td>210</td>\n",
       "      <td>10.539550</td>\n",
       "      <td>36.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.809524</td>\n",
       "      <td>120.219405</td>\n",
       "      <td>80.246914</td>\n",
       "      <td>73.943662</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>96</td>\n",
       "      <td>162</td>\n",
       "      <td>142</td>\n",
       "      <td>134</td>\n",
       "      <td>157</td>\n",
       "      <td>123</td>\n",
       "      <td>105</td>\n",
       "      <td>133</td>\n",
       "      <td>19.924949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cntyvtd county  vap_pop     density  vap_hisp_pct  vap_black_pct  \\\n",
       "0  025000018    Bee     1852   42.830818     46.004320       3.023758   \n",
       "1  025000013    Bee     1577   10.903907     62.396956       0.443881   \n",
       "2  025000009    Bee      764  723.040307     88.350785       1.701571   \n",
       "3  025000002    Bee      213    3.639055     33.333333       1.877934   \n",
       "4  025000008    Bee      210   10.539550     36.190476       0.000000   \n",
       "\n",
       "   vap_white_pct  dist_border  Pres_20_red_pct  Pres_16_red_pct  ...  \\\n",
       "0      50.971922   117.849478        73.809524        74.139729  ...   \n",
       "1      37.159163   111.368878        65.120968        59.210526  ...   \n",
       "2       9.947644   119.880787        42.953020        27.272727  ...   \n",
       "3      64.788732   112.012345        90.109890        91.351351  ...   \n",
       "4      63.809524   120.219405        80.246914        73.943662  ...   \n",
       "\n",
       "   Sen_12_Sadler  Sen_12_Cruz  Pres_20_votes  Pres_16_votes  Pres_12_votes  \\\n",
       "0            268          682           1134            959            994   \n",
       "1            273          412            992            760            712   \n",
       "2            273           87            447            429            387   \n",
       "3             25          129            182            185            165   \n",
       "4             37           96            162            142            134   \n",
       "\n",
       "   Sen_20_votes  Sen_18_votes  Sen_14_votes  Sen_12_votes       aland  \n",
       "0          1100           970           639           950   43.239893  \n",
       "1           930           655           445           685  144.627052  \n",
       "2           411           334           288           360    1.056649  \n",
       "3           176           167           119           154   58.531673  \n",
       "4           157           123           105           133   19.924949  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target column = Pres_20_red_blue_gap\n",
      "weight column = vap_pop\n",
      "predictors = ['vap_hisp_pct', 'vap_black_pct', 'vap_white_pct', 'density', 'dist_border']\n",
      "                             WLS Regression Results                             \n",
      "================================================================================\n",
      "Dep. Variable:     Pres_20_red_blue_gap   R-squared:                       0.684\n",
      "Model:                              WLS   Adj. R-squared:                  0.684\n",
      "Method:                   Least Squares   F-statistic:                     3773.\n",
      "Date:                  Sun, 10 Oct 2021   Prob (F-statistic):               0.00\n",
      "Time:                          17:46:17   Log-Likelihood:                -42403.\n",
      "No. Observations:                  8716   AIC:                         8.482e+04\n",
      "Df Residuals:                      8710   BIC:                         8.486e+04\n",
      "Df Model:                             5                                         \n",
      "Covariance Type:              nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "hisp           -0.1851      0.008    -22.057      0.000      -0.202      -0.169\n",
      "black          -0.9690      0.032    -30.607      0.000      -1.031      -0.907\n",
      "white           0.4999      0.012     40.363      0.000       0.476       0.524\n",
      "density        -0.0054      0.000    -50.795      0.000      -0.006      -0.005\n",
      "dist_border     0.0459      0.003     13.812      0.000       0.039       0.052\n",
      "hispblack      -0.0057      0.001     -5.553      0.000      -0.008      -0.004\n",
      "==============================================================================\n",
      "Omnibus:                     1674.320   Durbin-Watson:                   1.041\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            35163.278\n",
      "Skew:                          -0.348   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.815   Cond. No.                         425.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "###### Build VRA statistical models ######\n",
    "###### This cell defines, but does not run, the modeling functions. ######\n",
    "###### It does not produce any output, so it might not seem to do anything. ######\n",
    "###### You will specifty model parameters and run these functions later. ######\n",
    "\n",
    "import pandas as pd, statsmodels.api as sm\n",
    "# I will try to read VRA csv files from the local path below.\n",
    "# If that fails, I will try the google drive URL in model_votes.\n",
    "path = f'/home/jupyter/redistricting_data/'\n",
    "\n",
    "###### Helper functions ######\n",
    "def listify(x):\n",
    "    \"\"\"ensure x is a list\"\"\"\n",
    "    if x is None:\n",
    "        x = []\n",
    "    elif isinstance(x, str):\n",
    "        x = [x]\n",
    "    return x\n",
    "\n",
    "def check(x, valid):\n",
    "    \"\"\"check x is a valid value\"\"\"\n",
    "    bad = set(listify(x)).difference(valid)\n",
    "    assert len(bad)==0,  f'unknown {bad} ... must be one of {valid}'\n",
    "\n",
    "###### Define function that builds weighted least squares model  ######\n",
    "def model_votes(level, metric, election, races, predictors=None, interactions=None, const=True, weight='vap_pop'):\n",
    "    # Check valid inputs\n",
    "    valid_levels = {'county', 'cntyvtd'}\n",
    "    check(level, valid_levels)\n",
    "    try:\n",
    "        file = path + f'vra_{level}.csv'\n",
    "        df = pd.read_csv(file)\n",
    "        print(f'using local {file}')\n",
    "    except:\n",
    "        if level == 'county':\n",
    "            url = 'https://drive.google.com/file/d/143OH38F_fTqSnwwTBkkGsniBSeo8by18/view?usp=sharing'\n",
    "        else:\n",
    "            url = 'https://drive.google.com/file/d/149IB9m4YKcgrleAJTd44yJiu-7pHh0-n/view?usp=sharing'\n",
    "        url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "        df = pd.read_csv(url)\n",
    "        print(f'using remote {url}')\n",
    "    display(df.sample(n=3))\n",
    "\n",
    "    valid_elections = {x[:-8] for x in df.columns if 'red_pct' in x}\n",
    "    valid_metrics   = {'red_pct', 'red_blue_gap'}\n",
    "    valid_races     = {'hisp', 'black', 'white'}\n",
    "    \n",
    "    check(election, valid_elections)\n",
    "    check(metric  , valid_metrics)\n",
    "    check(races   , valid_races)\n",
    "    # if all races included, disable constant term to prevent colinearity\n",
    "    if valid_races.issubset(races):\n",
    "        const = False\n",
    "\n",
    "    target = f'{election}_{metric}'\n",
    "    races = {f'vap_{r}_pct': r for r in races}\n",
    "    predictors = list(races.keys()) + listify(predictors)\n",
    "    cols = [target, weight] + predictors\n",
    "    if const:\n",
    "        predictors.append('const')\n",
    "    print(f'target column = {target}\\nweight column = {weight}\\npredictors = {predictors}')\n",
    "    \n",
    "    # get columns we need and rename for convenience\n",
    "    X = df[cols].rename(columns=races)\n",
    "    \n",
    "    # create interaction columns\n",
    "    for a, b in listify(interactions):\n",
    "        X[a+b] = X[a] * X[b]\n",
    "    \n",
    "    # create constant column\n",
    "    if const:\n",
    "        X['const'] = 1.0\n",
    "\n",
    "    # drop rows with missing values - typically small vtds with no recorded votes in this election\n",
    "    X.dropna(inplace=True)\n",
    "    \n",
    "    # pop the target and weight columns from X\n",
    "    y = X.pop(target)\n",
    "    w = X.pop(weight)\n",
    "    \n",
    "    # create WLS model\n",
    "    mod_sm = sm.WLS(y, X, w)\n",
    "    res = mod_sm.fit()\n",
    "    print(res.summary())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Specify model options and call function above to generate it ######\n",
    "###### You may create many copies of this cell to try different model configurations ######\n",
    "opts = {'level'       : 'cntyvtd',\n",
    "        'metric'      : 'red_blue_gap',\n",
    "        'election'    : 'Pres_20',\n",
    "        'const'       : True,\n",
    "        'races'       : [\n",
    "            'hisp',\n",
    "            'black',\n",
    "            'white',\n",
    "        ],\n",
    "        'predictors'  : [\n",
    "            'density',\n",
    "            'dist_border',\n",
    "        ],\n",
    "        'interactions': [\n",
    "            ['hisp','black'],\n",
    "        ],\n",
    "       }\n",
    "res = model_votes(**opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5050a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Specify model options and call function above to generate it ######\n",
    "###### You may create many copies of this cell to try different model configurations ######\n",
    "opts = {'level'       : 'cntyvtd',\n",
    "        'metric'      : 'red_blue_gap',\n",
    "        'election'    : 'Pres_20',\n",
    "        'const'       : True,\n",
    "        'races'       : [\n",
    "            'hisp',\n",
    "            'black',\n",
    "            # 'white',\n",
    "        ],\n",
    "        'predictors'  : [\n",
    "            'density',\n",
    "            'dist_border',\n",
    "        ],\n",
    "        'interactions': [\n",
    "            ['hisp','black'],\n",
    "        ],\n",
    "       }\n",
    "res = model_votes(**opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12c678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/jupyter/MathVGerrmandering_CMAT_2021\n",
      "county\n",
      "cntyvtd\n"
     ]
    }
   ],
   "source": [
    "###### Generate Raw Data - Users cannot run this unless they have access to the source table in BigQuery ######\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%cd /home/jupyter/MathVGerrmandering_CMAT_2021/\n",
    "from src import *\n",
    "src_tbl = f'{data_bq}.TX_2020_cd_planc2100_cntyvtd_0_nodes'\n",
    "src_cols = get_cols(src_tbl)\n",
    "\n",
    "def get_vra(level):\n",
    "    if level == 'county':\n",
    "        labels = 'county'\n",
    "    elif level == 'cntyvtd':\n",
    "        labels = 'cntyvtd, county'\n",
    "    else:\n",
    "        raise Exception(f'invalid level {level}')\n",
    "\n",
    "    sels = []\n",
    "    votes = []\n",
    "    diff = []\n",
    "    red = []\n",
    "    def f(a, b):\n",
    "        short = dict()\n",
    "        for p in ['D', 'R']:\n",
    "            col = [x for x in src_cols if f'{a}_{p}' in x].pop()\n",
    "            nm = col.split('_')[3]\n",
    "            short[p] = f'{b}_{nm}'\n",
    "            sels.append(f'cast(sum({col}) as int) as {short[p]}')\n",
    "        votes.append(f'{short[\"D\"]} + {short[\"R\"]} as {b}_votes')\n",
    "        diff.append(f'case when {b}_votes > 0 then ({short[\"R\"]} - {short[\"D\"]}) / {b}_votes * 100 else Null end as {b}_red_blue_gap')\n",
    "        red .append(f'case when {b}_votes > 0 then  {short[\"R\"]} / {b}_votes * 100 else Null end as {b}_red_pct')\n",
    "\n",
    "    for yr in [2020, 2016, 2012]:\n",
    "        a = f'President_{yr}'\n",
    "        b = f'Pres_{yr%100}'\n",
    "        f(a, b)\n",
    "\n",
    "    for yr in [2020, 2018, 2014, 2012]:\n",
    "        a = f'USSen_{yr}'\n",
    "        b = f'Sen_{yr%100}'\n",
    "        f(a, b)\n",
    "\n",
    "    query = []\n",
    "    query.append(f\"\"\"\n",
    "select\n",
    "    {labels},\n",
    "    {join_str().join(sels)},\n",
    "    sum(vap_hisp_pop) as vap_hisp,\n",
    "    {' + '.join([f'sum({x})' for x in src_cols if 'vap_nonhisp' in x and 'black' in x])} as vap_black,\n",
    "    {' + '.join([f'sum({x})' for x in src_cols if 'vap_nonhisp' in x and 'white' in x and 'black' not in x])} as vap_white,\n",
    "    sum(aland) / {m_per_mi**2} as aland,\n",
    "    st_union_agg(polygon) as polygon,\n",
    "from\n",
    "    {src_tbl}\n",
    "group by\n",
    "    {labels}\n",
    "\"\"\")\n",
    "    \n",
    "    query.append(f\"\"\"\n",
    "select\n",
    "    *,\n",
    "    vap_hisp + vap_black + vap_white as vap_pop,\n",
    "    {join_str().join(votes)},\n",
    "from (\n",
    "    {subquery(query[-1])}\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "    query.append(f\"\"\"\n",
    "select\n",
    "    {labels},\n",
    "    vap_pop,\n",
    "    vap_pop / aland as density,\n",
    "    vap_hisp  / vap_pop * 100 as vap_hisp_pct,\n",
    "    vap_black / vap_pop * 100 as vap_black_pct,\n",
    "    vap_white / vap_pop * 100 as vap_white_pct,\n",
    "    st_distance(polygon, (select polygon from {data_bq}.countries where country = 'Mexico')) / {m_per_mi} as dist_border,\n",
    "    {join_str().join(red)},\n",
    "    {join_str().join(diff)},\n",
    "    vap_hisp,\n",
    "    vap_black,\n",
    "    vap_white,\n",
    "    * except ({labels}, vap_hisp, vap_black, vap_white, vap_pop, aland, polygon),\n",
    "    aland,\n",
    "    polygon,\n",
    "from (\n",
    "    {subquery(query[-1])}\n",
    "    )\n",
    "where vap_pop > 0\n",
    "\"\"\")\n",
    "    return query[-1]\n",
    "    \n",
    "for level in ['county', 'cntyvtd']:\n",
    "    print(level)\n",
    "    query = get_vra(level)\n",
    "    targ_tbl = f'{root_bq}.VRA.{level}'\n",
    "#     load_table(tbl=targ_tbl, query=query)\n",
    "    df = run_query(f'select * except (polygon) from {targ_tbl}')\n",
    "    f = data_path / f'vra_{level}.csv'\n",
    "    f.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(f, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
