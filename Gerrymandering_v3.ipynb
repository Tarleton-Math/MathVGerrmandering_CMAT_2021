{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floppy-participation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery-storage\n",
      "  Downloading google_cloud_bigquery_storage-2.4.0-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[K     |████████████████████████████████| 143 kB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: libcst>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery-storage) (0.3.18)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.22.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery-storage) (1.26.2)\n",
      "Requirement already satisfied: proto-plus>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery-storage) (1.18.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (2.25.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (2021.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (20.9)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (1.26.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (3.15.8)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (1.32.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (4.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.2 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.2.5->google-cloud-bigquery-storage) (3.7.4.3)\n",
      "Requirement already satisfied: pyyaml>=5.2 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.2.5->google-cloud-bigquery-storage) (5.3.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from libcst>=0.2.5->google-cloud-bigquery-storage) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-bigquery-storage) (2020.12.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-bigquery-storage) (0.4.3)\n",
      "Installing collected packages: google-cloud-bigquery-storage\n",
      "Successfully installed google-cloud-bigquery-storage-2.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google, dataclasses, numpy as np, pandas as pd, geopandas as gpd, networkx as nx\n",
    "import matplotlib.pyplot as plt, plotly.express as px \n",
    "from shapely.ops import orient\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient, types\n",
    "cred, proj = google.auth.default(scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "bqclient = bigquery.Client(credentials = cred, project = proj)\n",
    "proj_id = 'cmat-315920'\n",
    "crs_map = 'NAD83'\n",
    "crs_area = 'ESRI:102003'\n",
    "crs_length = 'ESRI:102005'\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "class myGeoDataFrame(gpd.GeoDataFrame):\n",
    "    def set_crs(self, crs='NAD83'):\n",
    "        self['centroid'] = self['centroid'].to_crs(crs)\n",
    "        self.to_crs(crs, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def get_perim(self, col=None):\n",
    "        X = self.set_crs(crs_length)\n",
    "        if col:\n",
    "            X = self.dissolve(by=col)\n",
    "        return X.length / 1000\n",
    "\n",
    "    def get_area(self, col=None):\n",
    "        X = self.set_crs(crs_area)\n",
    "        if col:\n",
    "            X = X.dissolve(by=col)\n",
    "        return X.area / (1000**2)\n",
    "    \n",
    "    def copy(self):\n",
    "        return self.__class__(super().copy())\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Gerry:\n",
    "    yr        : int = 2017\n",
    "    abbr      : str = 'RI'\n",
    "    min_degree: int = 2\n",
    "    # input is WKT in NAD83 - https://www2.census.gov/geo/pdfs/maps-data/data/tiger/tgrshp2020/TGRSHP2020_TechDoc_Ch3.pdf\n",
    "    # use ESRI:102003 for area calculations - https://epsg.io/102003\n",
    "    # use ESRI:102005 for length calculations - https://epsg.io/102005\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.congress = int((self.yr-1786)/2)\n",
    "        \n",
    "        query_str = f\"\"\"\n",
    "        select\n",
    "            state_fips_code as fips\n",
    "            , state_postal_abbreviation as abbr\n",
    "            , state_name as name\n",
    "        from\n",
    "            bigquery-public-data.census_utility.fips_codes_states\n",
    "        \"\"\"\n",
    "        states = bqclient.query(query_str).result().to_dataframe()\n",
    "        self.__dict__.update(states[states['abbr']==self.abbr].iloc[0])\n",
    "        \n",
    "    def get_bg_data(self):\n",
    "        query_str = f\"\"\"\n",
    "        select\n",
    "            --geo_id structure - https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html\n",
    "            geo.geo_id\n",
    "            , cast(substring(geo.geo_id, 0 , 2) as int) as state_fips\n",
    "            , cast(substring(geo.geo_id, 3 , 3) as int) as county_fips\n",
    "            , cast(substring(geo.geo_id, 5 , 6) as int) as tract_ce\n",
    "            , cast(substring(geo.geo_id, 12, 1) as int) as blockgroup_ce\n",
    "            , centroids.lon\n",
    "            , centroids.lat\n",
    "            , cast(cd.cd as int) as cd\n",
    "            , cast(acs.total_pop as int) as pop\n",
    "            , geo.geometry\n",
    "        from (\n",
    "            -- get shapes\n",
    "            select\n",
    "                geo_id\n",
    "                --state_fips_code as state_fips\n",
    "                --, county_fips_code as county_fips\n",
    "                --, tract_ce\n",
    "                --, blockgroup_ce\n",
    "                --, lsad_name\n",
    "                --, mtfcc_feature_class_code.\n",
    "                --, functional_status\n",
    "                --, area_land_meters\n",
    "                --, area_water_meters\n",
    "                --, internal_point_lat as lat\n",
    "                --, internal_point_lon aas loni\n",
    "                --, internal_point_geom\n",
    "                , blockgroup_geom as geometry\n",
    "            from\n",
    "                bigquery-public-data.geo_census_blockgroups.blockgroups_{self.fips}\n",
    "            )  as geo\n",
    "        inner join (\n",
    "            -- get shapes demographic data\n",
    "            select distinct\n",
    "                geo_id\n",
    "                , total_pop\n",
    "            from\n",
    "                bigquery-public-data.census_bureau_acs.blockgroup_{self.yr}_5yr\n",
    "            ) as acs\n",
    "        on\n",
    "            geo.geo_id = acs.geo_id\n",
    "        inner join (\n",
    "            -- get population weighted centroids\n",
    "            -- must build geo_id because data source does not include it\n",
    "            select distinct\n",
    "                concat( \n",
    "                    lpad(cast(STATEFP as string), 2, \"0\"),\n",
    "                    lpad(cast(COUNTYFP as string), 3, \"0\"),\n",
    "                    lpad(cast(TRACTCE as string), 6, \"0\"),\n",
    "                    lpad(cast(BLKGRPCE as string), 1, \"0\")\n",
    "                    ) as geo_id\n",
    "                --, POPULATION as pop\n",
    "                , LONGITUDE as lon\n",
    "                , LATITUDE as lat\n",
    "            from\n",
    "                {proj_id}.BLOCK_CENTROIDS.block_centroid_{self.fips}\n",
    "            ) as centroids\n",
    "        on\n",
    "            geo.geo_id = centroids.geo_id\n",
    "        inner join (\n",
    "            -- get congressional district\n",
    "            -- at block level -> must aggregate to blockgroup\n",
    "            -- 7141 (3%) of blockgroups span multiple congressional districts\n",
    "            -- We assign that entire bg to the cd with the most blocks\n",
    "            select\n",
    "                *\n",
    "            from (\n",
    "                select\n",
    "                    A.*\n",
    "                    , rank() over (partition by A.geo_id order by A.num_blocks_in_cd desc) as r\n",
    "                from (\n",
    "                    select\n",
    "                        left(BLOCKID, 12) as geo_id   -- remove last 4 char to get blockgroup geo_id\n",
    "                        , CD{self.congress} as cd\n",
    "                        , count(*) as num_blocks_in_cd\n",
    "                    from \n",
    "                        {proj_id}.Block_Equivalency_Files.{self.congress}th_BEF\n",
    "                    group by\n",
    "                        1, 2\n",
    "                    ) as A\n",
    "                ) as B\n",
    "            where\n",
    "                r = 1\n",
    "            ) as cd\n",
    "        on\n",
    "            geo.geo_id = cd.geo_id\n",
    "        \"\"\"\n",
    "        bg = bqclient.query(query_str).result().to_dataframe().set_index('geo_id')\n",
    "        bg['geometry'] = gpd.GeoSeries.from_wkt(bg['geometry']).apply(lambda p: orient(p, -1))\n",
    "        bg = myGeoDataFrame(bg, geometry='geometry', crs=crs_map)\n",
    "        bg['centroid'] = gpd.points_from_xy(bg['lon'], bg['lat'], crs=crs_map)\n",
    "        bg['area'] = bg.get_area()\n",
    "        bg['perim'] = bg.get_perim()\n",
    "        self.bg = bg\n",
    "        self.cds = np.unique(bg['cd'])\n",
    "\n",
    "    def get_bg_pairs(self):\n",
    "        cols = ['geo_id', 'geometry', 'centroid']\n",
    "        A = self.bg.reset_index().query('pop > 0')[cols]\n",
    "        pairs = A.merge(A, how='cross').query('geo_id_x < geo_id_y').reset_index(drop=True)\n",
    "        pairs['distance']     = pairs.set_geometry('centroid_x').distance(    pairs.set_geometry('centroid_y'), align=False)\n",
    "        pairs['perim_shared'] = pairs.set_geometry('geometry_x').intersection(pairs.set_geometry('geometry_y'), align=False).length\n",
    "        pairs['touch'] = pairs['perim_shared'] > 1\n",
    "        pairs['transit_time'] = pairs['distance'] / 1341 * rng.uniform(0.5, 1.5)  # 50 mph → 1341 m/min\n",
    "        pairs.drop(columns=[c+z for c in cols[1:] for z in ['_x', '_y']], inplace=True)\n",
    "        self.pairs = pd.concat([pairs, pairs.rename(columns={'geo_id_x':'geo_id_y', 'geo_id_y':'geo_id_x'})])\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "g = Gerry()\n",
    "g.get_bg_data()\n",
    "g.get_bg_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immediate-combining",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-690418290c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fips'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0mcds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "def get_data(fips):\n",
    "    query_str = f\"\"\"\n",
    "    select\n",
    "        --geo_id structure - https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html\n",
    "        geo.geo_id\n",
    "        , cast(substring(geo.geo_id, 0 , 2) as int) as state_fips\n",
    "        , cast(substring(geo.geo_id, 3 , 3) as int) as county_fips\n",
    "        , cast(substring(geo.geo_id, 5 , 6) as int) as tract_ce\n",
    "        , cast(substring(geo.geo_id, 12, 1) as int) as blockgroup_ce\n",
    "        , centroids.lon\n",
    "        , centroids.lat\n",
    "        , cast(cd.cd as int) as cd\n",
    "        , cast(acs.total_pop as int) as pop\n",
    "        , geo.geometry\n",
    "    from (\n",
    "        -- get shapes\n",
    "        select\n",
    "            geo_id\n",
    "            --state_fips_code as state_fips\n",
    "            --, county_fips_code as county_fips\n",
    "            --, tract_ce\n",
    "            --, blockgroup_ce\n",
    "            --, lsad_name\n",
    "            --, mtfcc_feature_class_code.\n",
    "            --, functional_status\n",
    "            --, area_land_meters\n",
    "            --, area_water_meters\n",
    "            --, internal_point_lat as lat\n",
    "            --, internal_point_lon aas loni\n",
    "            --, internal_point_geom\n",
    "            , blockgroup_geom as geometry\n",
    "        from\n",
    "            bigquery-public-data.geo_census_blockgroups.blockgroups_{fips}\n",
    "        )  as geo\n",
    "    inner join (\n",
    "        -- get shapes demographic data\n",
    "        select distinct\n",
    "            geo_id\n",
    "            , total_pop\n",
    "        from\n",
    "            bigquery-public-data.census_bureau_acs.blockgroup_{yr}_5yr\n",
    "        ) as acs\n",
    "    on\n",
    "        geo.geo_id = acs.geo_id\n",
    "    inner join (\n",
    "        -- get population weighted centroids\n",
    "        -- must build geo_id because data source does not include it\n",
    "        select distinct\n",
    "            concat( \n",
    "                lpad(cast(STATEFP as string), 2, \"0\"),\n",
    "                lpad(cast(COUNTYFP as string), 3, \"0\"),\n",
    "                lpad(cast(TRACTCE as string), 6, \"0\"),\n",
    "                lpad(cast(BLKGRPCE as string), 1, \"0\")\n",
    "                ) as geo_id\n",
    "            --, POPULATION as pop\n",
    "            , LONGITUDE as lon\n",
    "            , LATITUDE as lat\n",
    "        from\n",
    "            {proj_id}.BLOCK_CENTROIDS.block_centroid_{fips}\n",
    "        ) as centroids\n",
    "    on\n",
    "        geo.geo_id = centroids.geo_id\n",
    "    inner join (\n",
    "        -- get congressional district\n",
    "        -- at block level -> must aggregate to blockgroup\n",
    "        -- 7141 (3%) of blockgroups span multiple congressional districts\n",
    "        -- We assign that entire bg to the cd with the most blocks\n",
    "        select\n",
    "            *\n",
    "        from (\n",
    "            select\n",
    "                A.*\n",
    "                , rank() over (partition by A.geo_id order by A.num_blocks_in_cd desc) as r\n",
    "            from (\n",
    "                select\n",
    "                    left(BLOCKID, 12) as geo_id   -- remove last 4 char to get blockgroup geo_id\n",
    "                    , CD{self.congress} as cd\n",
    "                    , count(*) as num_blocks_in_cd\n",
    "                from \n",
    "                    {PROJ_ID}.Block_Equivalency_Files.{self.congress}th_BEF\n",
    "                group by\n",
    "                    1, 2\n",
    "                ) as A\n",
    "            ) as B\n",
    "        where\n",
    "            r = 1\n",
    "        ) as cd\n",
    "    on\n",
    "        geo.geo_id = cd.geo_id\n",
    "    \"\"\"\n",
    "    df = bqclient.query(query_str).result().to_dataframe().set_index('geo_id')\n",
    "    df['geometry'] = gpd.GeoSeries.from_wkt(df['geometry']).apply(lambda p: orient(p, -1))\n",
    "    df = myGeoDataFrame(df, geometry='geometry', crs=crs_map)\n",
    "    df['centroid'] = gpd.points_from_xy(df['lon'], df['lat'], crs=crs_map)\n",
    "    df['area'] = df.get_area()\n",
    "    df['perim'] = df.get_perim()\n",
    "    return df\n",
    "\n",
    "df = get_data(state['fips'])\n",
    "cds = np.unique(df['cd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(df, min_degree=4):\n",
    "    cols = ['geo_id', 'geometry', 'centroid']\n",
    "    A = df.reset_index().query('pop > 0')[cols]\n",
    "    pairs = A.merge(A, how='cross').query('geo_id_x < geo_id_y').reset_index(drop=True)\n",
    "    pairs['distance']     = pairs.set_geometry('centroid_x').distance(    pairs.set_geometry('centroid_y'), align=False)\n",
    "    pairs['perim_shared'] = pairs.set_geometry('geometry_x').intersection(pairs.set_geometry('geometry_y'), align=False).length\n",
    "    pairs['touch'] = pairs['perim_shared'] > 1\n",
    "    pairs['transit_time'] = pairs['distance'] / 1341 * rng.uniform(0.5, 1.5)  # 50 mph → 1341 m/min\n",
    "    pairs.drop(columns=[c+z for c in cols[1:] for z in ['_x', '_y']], inplace=True)\n",
    "    pairs = pd.concat([pairs, pairs.rename(columns={'geo_id_x':'geo_id_y', 'geo_id_y':'geo_id_x'})])\n",
    "    return pairs\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "pairs = get_pairs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_to_graph(edges):\n",
    "    edge_attr = ['perim_shared', 'touch', 'distance', 'transit_time']\n",
    "    return nx.from_pandas_edgelist(edges, source='geo_id_x', target='geo_id_y', edge_attr=edge_attr)\n",
    "\n",
    "def connect_districts(pairs, nodes, G):\n",
    "    for cd, X in nodes.groupby('cd'):\n",
    "        while True:\n",
    "            H = G.subgraph(X.index)\n",
    "            components = list(nx.connected_components(H))\n",
    "            print(f'CD {cd} has {len(components)} connected components')\n",
    "            if len(components) == 1:\n",
    "                break\n",
    "            mask = pairs['geo_id_x'].isin(components[0]) & pairs['geo_id_y'].isin(components[1])\n",
    "            i = pairs.loc[mask]['distance'].idxmin()\n",
    "            edges = pairs.loc[i]\n",
    "            G.update(edges_to_graph(edges))\n",
    "    return G\n",
    "\n",
    "def make_min_degree(pairs, G, min_degree):\n",
    "    edges = list()\n",
    "    for node, deg in G.degree:\n",
    "        n = min_degree - deg\n",
    "        if n > 0:\n",
    "            print(node,deg)\n",
    "            mask = (pairs['geo_id_x'] == node) & ~(pairs['geo_id_y'].isin(G.neighbors(node)))\n",
    "            edges.append(pairs[mask].nsmallest(n, 'distance'))\n",
    "    if len(edges) > 0:\n",
    "        G.update(edges_to_graph(pd.concat(edges)))\n",
    "    return G\n",
    "\n",
    "def make_graph(pairs, nodes, min_degree=2):\n",
    "    edges = pairs[pairs['touch']]\n",
    "    G = edges_to_graph(edges)\n",
    "    node_attr = ['area', 'perim', 'cd', 'pop']\n",
    "    nx.set_node_attributes(G, nodes[node_attr].to_dict('index'))\n",
    "\n",
    "    G = connect_districts(pairs, nodes, G)\n",
    "    G = make_min_degree(pairs, G, min_degree)\n",
    "    return G\n",
    "            \n",
    "G = make_graph(pairs, nodes=df, min_degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_map = df.copy().set_crs(crs_map).sort_values('cd')\n",
    "df_map['geometry'] = df_map['geometry'].simplify(0.001)\n",
    "df_map['cd_pop'] = df_map.groupby('cd')['pop'].transform('sum')\n",
    "df_map['cd_label'] = df_map['cd'].astype(str) + ': pop=' + df_map['cd_pop'].astype(str)\n",
    "\n",
    "fig = px.choropleth(df_map,\n",
    "                    geojson=df_map['geometry'],\n",
    "                    locations=df_map.index,\n",
    "                    color=\"cd_label\",\n",
    "                    hover_data={'area': ':.0f',\n",
    "                                'pop' : ':',\n",
    "                               }\n",
    "                   )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=True)\n",
    "fig.update_layout({\n",
    "    'title' : {'text':f'{state[\"name\"]} {yr}', 'x':0.5, 'y':1.0},\n",
    "    'margin' : {\"r\":0,\"t\":20,\"l\":0,\"b\":0},\n",
    "})\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
